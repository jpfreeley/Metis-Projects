{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is this?\n",
    "In this file I piece together all of the components from the previous jupyter notebooks. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below code was edited from code I found on a [reddit post](https://www.reddit.com/r/dailyprogrammer/comments/3snorf/20151113_challenge_240_hard_kenken_solver/). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Puzzle 1:\n",
      "1 4 3 5 2 6\n",
      "3 5 2 6 4 1\n",
      "4 6 1 3 5 2\n",
      "5 3 6 2 1 4\n",
      "6 2 4 1 3 5\n",
      "2 1 5 4 6 3\n",
      "Puzzle 2:\n",
      "3 2 1 4\n",
      "4 1 3 2\n",
      "2 3 4 1\n",
      "1 4 2 3\n"
     ]
    }
   ],
   "source": [
    "from functools import reduce\n",
    "import operator\n",
    "\n",
    "def check(board, cage_map, cell, i):\n",
    "    val, op, coords = cage_map[cell]\n",
    "    vals = [board[coord] for coord in coords]\n",
    "    if not all(vals):\n",
    "        return True\n",
    "    if op == \"=\":\n",
    "        return i == val\n",
    "    elif op == \"+\":\n",
    "        return sum(vals) == val\n",
    "    elif op == \"*\":\n",
    "        return reduce(operator.mul, vals) == val\n",
    "    elif op == \"-\":\n",
    "        return abs(vals[0] - vals[1]) == val\n",
    "    elif op == \"/\":\n",
    "        bigger, smaller = max(vals), min(vals)\n",
    "        return bigger % smaller == 0 and bigger // smaller == val\n",
    "\n",
    "def recurse(sz, cage_map, board, cell_list, depth=0):\n",
    "    if depth == len(cell_list):\n",
    "        return True\n",
    "    cell = cell_list[depth]\n",
    "    X, Y = cell\n",
    "    used = {board[(x, Y)] for x in range(sz)} | {board[(X, y)] for y in range(sz)}\n",
    "    for i in set(range(1, sz+1)) - used:\n",
    "        board[cell] = i\n",
    "        if not check(board, cage_map, cell, i):\n",
    "            continue\n",
    "        if recurse(sz, cage_map, board, cell_list, depth+1):\n",
    "            return True\n",
    "    board[cell] = None\n",
    "\n",
    "def read_file(file_name):\n",
    "    sz, *cages = open(file_name).read().splitlines()\n",
    "    sz = int(sz)\n",
    "\n",
    "    name_to_coord = lambda name: ('ABCDEFGHI'.index(name[0]), int(name[1])-1)\n",
    "    cages = [\n",
    "        (int(val), operator, [name_to_coord(coord) for coord in coords])\n",
    "        for val, operator, *coords in map(str.split, cages)\n",
    "    ]\n",
    "    \n",
    "    cage_map = {\n",
    "        coord: cage\n",
    "        for cage in cages\n",
    "        for coord in cage[2]\n",
    "    }\n",
    "\n",
    "    board = {\n",
    "        coord: None for coord in cage_map\n",
    "    }\n",
    "    cell_list = list(sorted(board))\n",
    "    \n",
    "    return sz, cage_map, board, cell_list\n",
    "    \n",
    "\n",
    "def solve_puzzle(file_name, verbose=False):\n",
    "    sz, cage_map, board, cell_list = read_file(file_name)\n",
    "    recurse(sz, cage_map, board, cell_list)\n",
    "\n",
    "    if verbose:\n",
    "        for y in range(sz):\n",
    "            line = \" \".join(str(board[(x, y)]) for x in range(sz))\n",
    "            print(line)\n",
    "    else:\n",
    "        return board\n",
    "        \n",
    "print('Puzzle 1:')\n",
    "solve_puzzle(\"puzzle.txt\", True)\n",
    "print('Puzzle 2:')\n",
    "solve_puzzle(\"puzzle2.txt\", True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's put everthing together now so we can get a **text file** lke those used in the above code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from copy import deepcopy\n",
    "import os\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from scipy import ndimage as ndi\n",
    "from scipy.misc import imsave\n",
    "\n",
    "from skimage import feature\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.transform import resize\n",
    "from skimage.morphology import erosion, dilation, rectangle, square\n",
    "from skimage.measure import find_contours\n",
    "\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "IMAGE_FILE = 'sample4x4_3.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def binarize(matrix, threshold=0.3):\n",
    "    temp = deepcopy(matrix)\n",
    "    for m in range(len(temp)):\n",
    "        for n in range(len(temp[m])):\n",
    "            if temp[m][n] < threshold:\n",
    "                temp[m][n] = 0.0\n",
    "            else:\n",
    "                temp[m][n] = 1.0\n",
    "                \n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "choosing  (25, 25)\n",
      "currently labeled  []\n",
      "path found :  [(25, 75), (25, 25)]\n",
      "assigning label :  1 \n",
      "\n",
      "choosing  (25, 75)\n",
      "currently labeled  [(25, 75), (25, 25)]\n",
      "its already in the set\n",
      "choosing  (25, 125)\n",
      "currently labeled  [(25, 75), (25, 25)]\n",
      "path found :  [(25, 125), (75, 175), (25, 175)]\n",
      "assigning label :  2 \n",
      "\n",
      "choosing  (25, 175)\n",
      "currently labeled  [(25, 125), (25, 75), (75, 175), (25, 25), (25, 175)]\n",
      "its already in the set\n",
      "choosing  (75, 25)\n",
      "currently labeled  [(25, 125), (25, 75), (75, 175), (25, 25), (25, 175)]\n",
      "path found :  [(125, 25), (75, 25)]\n",
      "assigning label :  3 \n",
      "\n",
      "choosing  (75, 75)\n",
      "currently labeled  [(25, 125), (25, 75), (75, 175), (25, 25), (25, 175), (125, 25), (75, 25)]\n",
      "path found :  [(75, 75), (125, 75)]\n",
      "assigning label :  4 \n",
      "\n",
      "choosing  (75, 125)\n",
      "currently labeled  [(25, 125), (25, 75), (75, 175), (75, 75), (25, 25), (125, 75), (25, 175), (125, 25), (75, 25)]\n",
      "path found :  [(175, 125), (125, 125), (75, 125)]\n",
      "assigning label :  5 \n",
      "\n",
      "choosing  (75, 175)\n",
      "currently labeled  [(25, 125), (25, 75), (75, 75), (125, 125), (25, 25), (125, 75), (75, 125), (125, 25), (175, 125), (25, 175), (75, 175), (75, 25)]\n",
      "its already in the set\n",
      "choosing  (125, 25)\n",
      "currently labeled  [(25, 125), (25, 75), (75, 175), (75, 75), (125, 125), (25, 25), (125, 75), (75, 125), (175, 125), (25, 175), (125, 25), (75, 25)]\n",
      "its already in the set\n",
      "choosing  (125, 75)\n",
      "currently labeled  [(25, 125), (25, 75), (75, 75), (125, 125), (25, 25), (125, 75), (75, 125), (175, 125), (125, 25), (25, 175), (75, 175), (75, 25)]\n",
      "its already in the set\n",
      "choosing  (125, 125)\n",
      "currently labeled  [(25, 125), (25, 75), (75, 175), (75, 75), (125, 125), (25, 25), (125, 75), (75, 125), (175, 125), (25, 175), (125, 25), (75, 25)]\n",
      "its already in the set\n",
      "choosing  (125, 175)\n",
      "currently labeled  [(25, 125), (25, 75), (75, 75), (125, 125), (25, 25), (125, 75), (75, 125), (175, 125), (125, 25), (25, 175), (75, 175), (75, 25)]\n",
      "path found :  [(125, 175), (175, 175)]\n",
      "assigning label :  6 \n",
      "\n",
      "choosing  (175, 25)\n",
      "currently labeled  [(25, 125), (125, 175), (25, 75), (75, 175), (75, 75), (125, 125), (25, 25), (125, 75), (75, 125), (175, 125), (25, 175), (125, 25), (75, 25), (175, 175)]\n",
      "path found :  [(175, 75), (175, 25)]\n",
      "assigning label :  7 \n",
      "\n",
      "choosing  (175, 75)\n",
      "currently labeled  [(25, 125), (25, 75), (75, 75), (125, 125), (175, 25), (25, 25), (125, 75), (75, 125), (75, 25), (175, 75), (175, 125), (125, 25), (25, 175), (75, 175), (125, 175), (175, 175)]\n",
      "its already in the set\n",
      "choosing  (175, 125)\n",
      "currently labeled  [(25, 125), (125, 175), (25, 75), (75, 175), (75, 75), (125, 125), (175, 25), (25, 25), (125, 75), (75, 125), (175, 75), (175, 125), (25, 175), (125, 25), (75, 25), (175, 175)]\n",
      "its already in the set\n",
      "choosing  (175, 175)\n",
      "currently labeled  [(25, 125), (25, 75), (75, 75), (125, 125), (175, 25), (25, 25), (125, 75), (75, 125), (175, 75), (75, 25), (175, 125), (125, 25), (25, 175), (75, 175), (125, 175), (175, 175)]\n",
      "its already in the set\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQQAAAEACAYAAABVmQgcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nqRBExPv/NCbYSqt6pE0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x108d43a58>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "###########################\n",
    "#####IMPORT THE IMAGE######\n",
    "###########################\n",
    "sample4x4_orig = ndi.imread(IMAGE_FILE, mode='L')\n",
    "sample4x4 = resize(sample4x4_orig, (200,200))\n",
    "#plt.imshow(sample4x4, cmap=mpl.cm.Greys_r)\n",
    "\n",
    "binar = deepcopy(sample4x4)\n",
    "binar = binarize(binar)\n",
    "#plt.imshow(binar, cmap=mpl.cm.Greys_r)\n",
    "\n",
    "###########################\n",
    "#####CROP THE IMAGE########\n",
    "###########################\n",
    "# up left\n",
    "cond = False\n",
    "for m in range(7):\n",
    "    for n in range(7):\n",
    "        if binar[m][n] == 0:\n",
    "            up_left = [m,n]\n",
    "            cond = True\n",
    "            break\n",
    "    if cond==True:\n",
    "        break\n",
    "        \n",
    "# low right\n",
    "cond = False\n",
    "for m in range(199,192,-1):\n",
    "    for n in range(199,192,-1):\n",
    "        #print(m,n, binar[m][n])\n",
    "        if binar[m][n] == 0:\n",
    "            low_right = [m,n]\n",
    "            cond = True\n",
    "            break\n",
    "    if cond==True:\n",
    "        break\n",
    "\n",
    "sample4x4_crop = resize(sample4x4[up_left[0]:low_right[0]+1,up_left[1]:low_right[1]+1], (200,200))\n",
    "binar = binarize(sample4x4_crop)\n",
    "plt.imshow(binar, cmap=mpl.cm.Greys_r)\n",
    "\n",
    "################################################\n",
    "#####APPLY FILTERS TO REMOVE NUM/SYMBOLS########\n",
    "################################################\n",
    "selem = rectangle(2,2)\n",
    "dil = dilation(binar, selem)\n",
    "#dil = erosion(dil)\n",
    "#plt.imshow(dil, cmap=mpl.cm.Greys_r)\n",
    "\n",
    "dil = binarize(dil)\n",
    "#plt.imshow(dil, cmap=mpl.cm.Greys_r)\n",
    "\n",
    "cluster_image = deepcopy(dil)\n",
    "\n",
    "for i in range(4):\n",
    "    for j in range(4):\n",
    "        cluster_image[i*50+5:i*50+40,j*50+3:j*50+38] = np.zeros((35,35))+1\n",
    "\n",
    "#plt.imshow(cluster_image, cmap=mpl.cm.Greys_r)\n",
    "\n",
    "##################################\n",
    "#####GET CLUSTER LOCATIONS########\n",
    "##################################\n",
    "\n",
    "#GENERATE CENTERS OF EACH BOX\n",
    "CENTROIDS = [[[25+50*i,25+50*j] for j in range(0,4)] for i in range(0,4)]\n",
    "\n",
    "#LINK BOX CENTERS TO GRID LOCATIONS I.E. (25,175) = (0,3)\n",
    "CLUSTER_LOC_DICT = defaultdict(list)\n",
    "\n",
    "for m in range(len(CENTROIDS)):\n",
    "    for n in range(len(CENTROIDS[m])):\n",
    "        CLUSTER_LOC_DICT[tuple(CENTROIDS[m][n])] = (m,n)\n",
    "\n",
    "#CREATE A DICTIONARY OF THE LOCATIONS OF NEIGHBORS OF EACH BOX\n",
    "NEIGHBOR_PAIRS = []\n",
    "\n",
    "for m in range(len(CENTROIDS)):\n",
    "    for n in range(len(CENTROIDS[m])):\n",
    "        #skip right edge\n",
    "        if n < (len(CENTROIDS[m])-1):\n",
    "            NEIGHBOR_PAIRS.append([CENTROIDS[m][n], CENTROIDS[m][n+1]])\n",
    "        #skip bottom edge\n",
    "        if m < (len(CENTROIDS)-1):\n",
    "            NEIGHBOR_PAIRS.append([CENTROIDS[m][n], CENTROIDS[m+1][n]])\n",
    "        #skip top edge\n",
    "        if m > 0:\n",
    "            NEIGHBOR_PAIRS.append([CENTROIDS[m][n], CENTROIDS[m-1][n]])\n",
    "        #skip left edge\n",
    "        if n > 0:\n",
    "            NEIGHBOR_PAIRS.append([CENTROIDS[m][n], CENTROIDS[m][n-1]]) \n",
    "\n",
    "NEIGHBORS_DICT = defaultdict(list)\n",
    "\n",
    "for link in NEIGHBOR_PAIRS:\n",
    "    NEIGHBORS_DICT[tuple(link[0])].append(link[1])\n",
    "\n",
    "    \n",
    "#CREATE CLASS FOR WALKING THROUGH IMAGE AND RETURNING \n",
    "class cluster_grouper(object):\n",
    "    \n",
    "    def __init__ (self, image):\n",
    "        self.image_arr = image\n",
    "        # unique_label is the current # of unique labels used\n",
    "        self.unique_label = 1\n",
    "\n",
    "        # labeled_boxes keeps track of the boxes that have already been labeled\n",
    "        self.labeled_boxes = []\n",
    "\n",
    "        # create label_dict to store each boxes location\n",
    "        self.label_dict = {tuple(v):0 for _,v in CLUSTER_LOC_DICT.items()}\n",
    "                \n",
    "    \n",
    "        \n",
    "    def check_neighbors(self, box_to_check, path=[]):\n",
    "    #if neighbor is unlabeled and connected, \n",
    "    #step to that one, \n",
    "    #append current cell to path, \n",
    "    #call check neighbors\n",
    "        #check neighbors to see if any paths are blocked append T/F to if path blocked\n",
    "        if box_to_check not in path:\n",
    "            path.append(box_to_check)\n",
    "        \n",
    "        for neighbor in NEIGHBORS_DICT[box_to_check]:\n",
    "            # print(neighbor)\n",
    "            # skip a neighbor that you've come from\n",
    "            if tuple(neighbor) not in path:\n",
    "                top = box_to_check[0]\n",
    "                bottom = neighbor[0]\n",
    "                left = box_to_check[1]\n",
    "                right = neighbor[1]\n",
    "                \n",
    "                # need to check if top/bottom or left/right are same value, need to add 1\n",
    "                if top == bottom:\n",
    "                    bottom +=1\n",
    "                if left == right:\n",
    "                    right +=1\n",
    "                    \n",
    "                # also swap top/bottom or left/right if matching upwards or leftwards\n",
    "                if right < left:\n",
    "                    left,right = right,left\n",
    "                if top > bottom:\n",
    "                    top,bottom = bottom,top\n",
    "                \n",
    "                # if there is a black pixel in path, skip\n",
    "                if 0 in self.image_arr[top:bottom,left:right].flatten():\n",
    "                    continue\n",
    "                # else check the neighbor and extend path of result recursively\n",
    "                else:\n",
    "                    path.extend(self.check_neighbors(tuple(neighbor), path))\n",
    "                    path = list(set(path))\n",
    "                               \n",
    "        return path\n",
    "    \n",
    "    def execute(self):\n",
    "        for box in sorted(NEIGHBORS_DICT.keys(), key=lambda x: x):\n",
    "            #only clusters that haven't been labeled should appear not labeled,\n",
    "            #once an unlabeled cluster is found, all boxes in that cluster should be labeled\n",
    "            print('choosing ',box)\n",
    "            print('currently labeled ',self.labeled_boxes)\n",
    "            if box not in self.labeled_boxes:\n",
    "                #print(box)\n",
    "                connected_path = self.check_neighbors(box, path=[])\n",
    "                #get only unique boxes\n",
    "                print('path found : ', connected_path)\n",
    "                connected_path = set(connected_path)\n",
    "                #assign each box in the path a label\n",
    "                for connected_box in connected_path:\n",
    "                    self.label_dict[CLUSTER_LOC_DICT[connected_box]] = self.unique_label\n",
    "                    self.labeled_boxes.append(tuple(connected_box))\n",
    "                #increment the label\n",
    "                print('assigning label : ',self.unique_label, '\\n')\n",
    "                self.unique_label += 1\n",
    "            else:\n",
    "                print('its already in the set')\n",
    "            \n",
    "            self.labeled_boxes = list(set(self.labeled_boxes))\n",
    "        return self.label_dict\n",
    "\n",
    "#PASS THE CLUSTER IMAGE TO A NEW INSTANCE OF THE CLUSTER_GROUPER AND EXECUTE\n",
    "#THIS WILL RETURN A DICTIONARY WITH THE CLUSTER LABEL(VALUE) FOR EACH BOX(KEY)\n",
    "cluster_groupings_dict = cluster_grouper(cluster_image).execute()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identifying the numbers with TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 numbers/symbols found in quadrant 0,0\n",
      "0 numbers/symbols found in quadrant 0,1\n",
      "2 numbers/symbols found in quadrant 0,2\n",
      "0 numbers/symbols found in quadrant 0,3\n",
      "2 numbers/symbols found in quadrant 1,0\n",
      "2 numbers/symbols found in quadrant 1,1\n",
      "2 numbers/symbols found in quadrant 1,2\n",
      "0 numbers/symbols found in quadrant 1,3\n",
      "0 numbers/symbols found in quadrant 2,0\n",
      "0 numbers/symbols found in quadrant 2,1\n",
      "0 numbers/symbols found in quadrant 2,2\n",
      "2 numbers/symbols found in quadrant 2,3\n",
      "2 numbers/symbols found in quadrant 3,0\n",
      "0 numbers/symbols found in quadrant 3,1\n",
      "0 numbers/symbols found in quadrant 3,2\n",
      "0 numbers/symbols found in quadrant 3,3\n",
      "14 numbers/symbols found in image\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWIAAAD/CAYAAADL09xTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niB3HcXqMN8SO4zg9xhtix3GcHvP/ATeWmvI3ZM5AAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x104428780>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "##############################################\n",
    "#####IMPORT TENSOR FLOW GRAPH AND DATA########\n",
    "##############################################\n",
    "\n",
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def conv2d(x, W):\n",
    "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],\n",
    "                            strides=[1, 2, 2, 1], padding='SAME')\n",
    "    \n",
    "\n",
    "with tf.Graph().as_default():\n",
    "    x = tf.placeholder(tf.float32, shape=[None, 784])\n",
    "    y_ = tf.placeholder(tf.float32, shape=[None, 14])\n",
    "    W = tf.Variable(tf.zeros([784,14]))\n",
    "    b = tf.Variable(tf.zeros([14]))\n",
    "\n",
    "    #Inference\n",
    "    with tf.name_scope('hidden1'):\n",
    "        W_conv1 = weight_variable([5, 5, 1, 32])\n",
    "        b_conv1 = bias_variable([32])\n",
    "        x_image = tf.reshape(x, [-1,28,28,1])\n",
    "        hidden1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)\n",
    "\n",
    "    with tf.name_scope('hidden2'):\n",
    "        h_pool1 = max_pool_2x2(hidden1)\n",
    "        W_conv2 = weight_variable([5, 5, 32, 64])\n",
    "        b_conv2 = bias_variable([64])\n",
    "        h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n",
    "\n",
    "    with tf.name_scope('fully_connected'):\n",
    "        h_pool2 = max_pool_2x2(h_conv2)\n",
    "        W_fc1 = weight_variable([7 * 7 * 64, 1024])\n",
    "        b_fc1 = bias_variable([1024])\n",
    "        h_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*64])\n",
    "        fully_connected = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)\n",
    "\n",
    "    with tf.name_scope('dropout'):\n",
    "        keep_prob = tf.placeholder(tf.float32)\n",
    "        dropout = tf.nn.dropout(fully_connected, keep_prob)\n",
    "\n",
    "    with tf.name_scope('softmax'):\n",
    "        W_fc2 = weight_variable([1024, 14])\n",
    "        b_fc2 = bias_variable([14])\n",
    "        y_conv=tf.nn.softmax(tf.matmul(dropout, W_fc2) + b_fc2)\n",
    "\n",
    "    #Loss\n",
    "    cross_entropy = -tf.reduce_sum(y_*tf.log(y_conv), name='xentropy')\n",
    "\n",
    "    #Training\n",
    "    tf.scalar_summary(cross_entropy.op.name, cross_entropy)\n",
    "    global_step=tf.Variable(0,name='global_step',trainable=False)\n",
    "    train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy,global_step=global_step)\n",
    "\n",
    "    #Evaluation\n",
    "    correct_prediction = tf.equal(tf.argmax(y_conv,1), tf.argmax(y_,1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "    #Prediction\n",
    "    prediction = tf.argmax(y_conv,1)\n",
    "\n",
    "    #Initialization\n",
    "    sess = tf.Session()\n",
    "    init = tf.initialize_all_variables()\n",
    "    saver = tf.train.Saver()\n",
    "\n",
    "    sess.run(init)\n",
    "\n",
    "    #Restore\n",
    "    saver.restore(sess,\"model_newest.ckpt\")\n",
    "    \n",
    "################################################################\n",
    "#####PRE PROCESS THE IMAGE FOR ISOLATING NUMBERS/SYMBOLS########\n",
    "################################################################\n",
    "    \n",
    "def pre_process_image(image_file):\n",
    "    #get the image and resize\n",
    "    image_data = ndi.imread(image_file, mode = 'L')\n",
    "    resized_image = resize(image_data, (200,200))\n",
    "\n",
    "    #apply the transformations from 01_basic_image_tests.ipynb\n",
    "    binar = deepcopy(resized_image)\n",
    "    binar = binarize(binar, 0.6)\n",
    "\n",
    "    # Get the upleft and lowright black pixels for croping to corners\n",
    "    # up left\n",
    "    cond = False\n",
    "    for m in range(10):\n",
    "        for n in range(10):\n",
    "            if binar[m][n] == 0:\n",
    "                up_left = [m,n]\n",
    "                cond = True\n",
    "                break\n",
    "        if cond==True:\n",
    "            break\n",
    "\n",
    "    # low right\n",
    "    cond = False\n",
    "    for m in range(199,189,-1):\n",
    "        for n in range(199,189,-1):\n",
    "            #print(m,n, binar[m][n])\n",
    "            if binar[m][n] == 0:\n",
    "                low_right = [m,n]\n",
    "                cond = True\n",
    "                break\n",
    "        if cond==True:\n",
    "            break\n",
    "\n",
    "    resized_image = resize(resized_image[up_left[0]:low_right[0]+1,up_left[1]:low_right[1]+1], (200,200))\n",
    "    binar = binarize(resized_image, 0.4)\n",
    "\n",
    "    undilated = deepcopy(binar)\n",
    "\n",
    "    #dilate the binarized image\n",
    "    selem = rectangle(1,2)\n",
    "    dil = dilation(binar, selem)\n",
    "\n",
    "    #binarize dilation\n",
    "    dil = binarize(dil)\n",
    "\n",
    "    #final = dil\n",
    "\n",
    "    final = deepcopy(dil)\n",
    "    for i in range(4):\n",
    "        for j in range(4):\n",
    "            final[i*50+3:i*50+25,j*50+3:j*50+44] = undilated[i*50+3:i*50+25,j*50+3:j*50+44]\n",
    "\n",
    "    #Try to remove all borders and grid lines in the image. \n",
    "    #Do this by scanning over rows and cols and if more than 25%\n",
    "    #of the pixels are <= 0.45 then set the entire row to 1(white)\n",
    "\n",
    "    #first rows\n",
    "    for row in range(len(final)):\n",
    "        count = 0\n",
    "        for pixel in final[row,:]:\n",
    "            if pixel == 0:\n",
    "                count += 1\n",
    "        if count >= 48:\n",
    "            final[row,:] = final[row,:]*0 + 1\n",
    "\n",
    "    #columns\n",
    "    for col in range(len(final[0,:])):\n",
    "        count = 0\n",
    "        for pixel in final[:,col]:\n",
    "            if pixel == 0:\n",
    "                count += 1\n",
    "        if count >= 48:\n",
    "            final[:,col] = final[:,col]*0 + 1\n",
    "            \n",
    "    #add some final erosion (black) to fill out numbers and ensure they're connected\n",
    "    final = binarize(erosion(final, rectangle(1,2)),.0000001)\n",
    "    \n",
    "    return final\n",
    "\n",
    "#APPLY PRE PROCESS TO DESIRED IMAGE\n",
    "final = pre_process_image(IMAGE_FILE)\n",
    "\n",
    "\n",
    "#the regions in the image that will be searched for contours\n",
    "REGIONS_OF_INTEREST = [final[3:39,3:46],\n",
    "                      final[3:39,53:96],\n",
    "                      final[3:39,103:146],\n",
    "                      final[3:39,153:196],\n",
    "                      final[53:89,3:46],\n",
    "                      final[53:89,53:96],\n",
    "                      final[53:89,103:146],\n",
    "                      final[53:89,153:196],\n",
    "                      final[103:139,3:46],\n",
    "                      final[103:139,53:96],\n",
    "                      final[103:139,103:146],\n",
    "                      final[103:139,153:196],\n",
    "                      final[153:189,3:46],\n",
    "                      final[153:189,53:96],\n",
    "                      final[153:189,103:146],\n",
    "                      final[153:189,153:196]\n",
    "                      ]\n",
    "\n",
    "#CONVERSION used for converting the index of the argmax returned\n",
    "#from tensorflow into a string value\n",
    "CONVERSION = {0:'0',1:'1',2:'2',3:'3',4:'4',5:'5',6:'6',7:'7',8:'8',9:'9',10:'*', 11:'+',12:'-',13:'/'}\n",
    "\n",
    "\n",
    "def get_predictions(final):\n",
    "    ################################################################\n",
    "    #####ISOLATE LOCATIONS OF EACH NUM/SYM IN EACH BOX############## \n",
    "    #####       AND PREDICT USING TENSOR FLOW         ##############\n",
    "    ################################################################\n",
    "\n",
    "    #get the contour lines and make a bounding box of each contour\n",
    "    total_images_found = 0\n",
    "    fig = plt.figure()\n",
    "\n",
    "    #x_count and y_count is used for plotting the images\n",
    "    #and also for saving the results to prediction_dict\n",
    "    x_count = 0\n",
    "    y_count = 0\n",
    "    prediction_dict = defaultdict(list)\n",
    "    plot_counter = 1\n",
    "\n",
    "    for region in REGIONS_OF_INTEREST:  \n",
    "        #Results is where the sub-ROIs will be stored\n",
    "        results = []\n",
    "        ctrs = find_contours(region, .9)\n",
    "        rects = [np.array(\n",
    "                [[min(ctr, key=lambda x: x[0])[0],min(ctr, key=lambda x: x[1])[1]],\n",
    "                 [min(ctr, key=lambda x: x[0])[0],max(ctr, key=lambda x: x[1])[1]],\n",
    "                 [max(ctr, key=lambda x: x[0])[0],max(ctr, key=lambda x: x[1])[1]],\n",
    "                 [max(ctr, key=lambda x: x[0])[0],min(ctr, key=lambda x: x[1])[1]],\n",
    "                 [min(ctr, key=lambda x: x[0])[0],min(ctr, key=lambda x: x[1])[1]]])\n",
    "                  for ctr in ctrs]\n",
    "\n",
    "        #print(rects)\n",
    "\n",
    "        #loop over the bounding boxes and store that region, the regions will need \n",
    "        #to be filtered so that there aren't regions within regions\n",
    "        for rect in rects:\n",
    "            try:\n",
    "                pt1 = rect[0][0] #m min\n",
    "                pt2 = rect[2][0] #m max\n",
    "                pt3 = rect[0][1] #n min\n",
    "                pt4 = rect[1][1] #n max\n",
    "                results.append([pt1,pt2,pt3,pt4])\n",
    "\n",
    "            except:\n",
    "                print('There was an error')\n",
    "\n",
    "\n",
    "        #filter out a result contained in another result\n",
    "        #This isn't very efficient and will likely need a better\n",
    "        #algorithm for images taken with a camera but it works well for now\n",
    "        for result in results:\n",
    "            temp = [res for res in results if res != result]\n",
    "            for other in temp:\n",
    "                if result[0] >= other[0] and result[1] <= other[1] and\\\n",
    "                result[2] >= other[2] and result[3] <= other[3]:\n",
    "                    try:\n",
    "                        results.remove(result)\n",
    "                    except ValueError as e:\n",
    "                        print('Error removing result from results, ', e)\n",
    "\n",
    "        #combine those with similar midpoints (mainly used for finding division symbols)\n",
    "        midpoints = [(result[3]-result[2])/2+result[2] for result in results]\n",
    "\n",
    "        new_results = []\n",
    "        for i,result in enumerate(results):\n",
    "            diff = [j for j, m in enumerate(midpoints) if abs(m-midpoints[i]) < 3]\n",
    "            #need to reinitialize new_results between loops\n",
    "            if len(diff) > 1:\n",
    "                new_results = [result for j,result in enumerate(results) if j not in diff]\n",
    "                similar_obj = np.array([results[j] for j in diff])\n",
    "                new_object = np.array([min(similar_obj[:,0]),\n",
    "                                      max(similar_obj[:,1]),\n",
    "                                      min(similar_obj[:,2]),\n",
    "                                      max(similar_obj[:,3])])\n",
    "                #print(new_object)\n",
    "                new_results.append(list(new_object))\n",
    "\n",
    "                break\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "        #assign new_results to results if new results were obtained\n",
    "        try:\n",
    "            if len(new_results) > 0:\n",
    "                results = new_results\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "\n",
    "        #Sort the results by furthest box to the left \n",
    "        results = sorted(results, key=lambda x: x[2])\n",
    "\n",
    "        #now make a new prediction on the results:\n",
    "        new_results = []\n",
    "        for result in results:\n",
    "            new_res = deepcopy(result)\n",
    "            roi = region[int(result[0]):int(result[1])+1, int(result[2]):int(result[3])+1] \n",
    "            roi = resize(roi, (28, 28)).reshape(1,784)\n",
    "            nbr = prediction.eval(feed_dict={x:roi, keep_prob:1.0}, session=sess)[0]\n",
    "            prediction_dict[(x_count,y_count)].append(CONVERSION[nbr])\n",
    "            new_res.append(CONVERSION[nbr])\n",
    "            new_results.append(new_res)\n",
    "\n",
    "\n",
    "        try:\n",
    "            if len(new_results) > 0:\n",
    "                results = new_results\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        #Set the value of a box to an empty list in prediction_dict if no results\n",
    "        if len(results) == 0:\n",
    "            prediction_dict[(x_count,y_count)] = []\n",
    "\n",
    "        #Plot all of the subplots\n",
    "        plt.subplot(4,4,plot_counter)\n",
    "        plot_counter+=1\n",
    "        plt.imshow(region, interpolation='nearest', cmap=plt.cm.gray)\n",
    "\n",
    "        '''for contour in rects:\n",
    "            plt.plot(contour[:, 1], contour[:, 0], linewidth=2)'''\n",
    "\n",
    "        z = 0\n",
    "        for res in results:\n",
    "            plt.annotate('{}'.format(res[4]), xy=(10+z*5,25))\n",
    "            z+=1\n",
    "\n",
    "        #Loop again over the filtered results, count how many there are\n",
    "        num_sym_found = 0\n",
    "        for result in results:\n",
    "            num_sym_found += 1      \n",
    "\n",
    "        print('{} numbers/symbols found in quadrant {},{}'.format(num_sym_found, x_count,y_count))\n",
    "        y_count+=1\n",
    "        if y_count == 4:\n",
    "            y_count = 0\n",
    "            x_count += 1\n",
    "        total_images_found+=num_sym_found\n",
    "\n",
    "    print('{} numbers/symbols found in image'.format(total_images_found))\n",
    "\n",
    "    return prediction_dict\n",
    "\n",
    "prediction_dict = get_predictions(final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the text file\n",
    "The key pieces of info we have now is cluster_groupings_dict and prediction_dict. Now combine these two to get the text file.\n",
    "\n",
    "General format of the text file is:\n",
    "\n",
    "```\n",
    "4\n",
    "16 * A1 B1\n",
    "7 + C1 D1\n",
    "2 - A2 A3\n",
    "4 = D2\n",
    "...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(0, 0): 1,\n",
       " (0, 1): 1,\n",
       " (0, 2): 2,\n",
       " (0, 3): 2,\n",
       " (1, 0): 3,\n",
       " (1, 1): 4,\n",
       " (1, 2): 5,\n",
       " (1, 3): 2,\n",
       " (2, 0): 3,\n",
       " (2, 1): 4,\n",
       " (2, 2): 5,\n",
       " (2, 3): 6,\n",
       " (3, 0): 7,\n",
       " (3, 1): 7,\n",
       " (3, 2): 5,\n",
       " (3, 3): 6}"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_groupings_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list,\n",
       "            {(0, 0): ['5', '+'],\n",
       "             (0, 1): [],\n",
       "             (0, 2): ['8', '*'],\n",
       "             (0, 3): [],\n",
       "             (1, 0): ['2', '/'],\n",
       "             (1, 1): ['2', '-'],\n",
       "             (1, 2): ['9', '+'],\n",
       "             (1, 3): [],\n",
       "             (2, 0): [],\n",
       "             (2, 1): [],\n",
       "             (2, 2): [],\n",
       "             (2, 3): ['2', '-'],\n",
       "             (3, 0): ['4', '*'],\n",
       "             (3, 1): [],\n",
       "             (3, 2): [],\n",
       "             (3, 3): []})"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list,\n",
       "            {(0, 0): ['5', '+'],\n",
       "             (0, 1): [],\n",
       "             (0, 2): ['8', '*'],\n",
       "             (0, 3): [],\n",
       "             (1, 0): ['2', '/'],\n",
       "             (1, 1): ['2', '-'],\n",
       "             (1, 2): ['9', '+'],\n",
       "             (1, 3): [],\n",
       "             (2, 0): [],\n",
       "             (2, 1): [],\n",
       "             (2, 2): [],\n",
       "             (2, 3): ['2', '-'],\n",
       "             (3, 0): ['4', '*'],\n",
       "             (3, 1): [],\n",
       "             (3, 2): [],\n",
       "             (3, 3): []})"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#combine numbers into single number and add '=' if no operation\n",
    "for k,v in prediction_dict.items():\n",
    "    if len(v) > 0:\n",
    "        if v[-1] not in '+-*/':\n",
    "            operation = '='\n",
    "            number = ''.join(v[:])\n",
    "        else:\n",
    "            operation = v[-1]\n",
    "            number = ''.join(v[:-1])\n",
    "        \n",
    "        prediction_dict[k] = [number, operation]\n",
    "        \n",
    "prediction_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a new dictionary for the naming convention of squares in the KenKen algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(0, 0): 'A1',\n",
       " (0, 1): 'B1',\n",
       " (0, 2): 'C1',\n",
       " (0, 3): 'D1',\n",
       " (1, 0): 'A2',\n",
       " (1, 1): 'B2',\n",
       " (1, 2): 'C2',\n",
       " (1, 3): 'D2',\n",
       " (2, 0): 'A3',\n",
       " (2, 1): 'B3',\n",
       " (2, 2): 'C3',\n",
       " (2, 3): 'D3',\n",
       " (3, 0): 'A4',\n",
       " (3, 1): 'B4',\n",
       " (3, 2): 'C4',\n",
       " (3, 3): 'D4'}"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kenken4_4blocks = ['A1', 'B1', 'C1', 'D1',\n",
    "                   'A2', 'B2', 'C2', 'D2',\n",
    "                   'A3', 'B3', 'C3', 'D3',\n",
    "                   'A4', 'B4', 'C4', 'D4']\n",
    "block_conversion = {x[0]:kenken4_4blocks[i] for i, x in \n",
    "                    enumerate(sorted(prediction_dict.items(), key=lambda z:(z[0][0], z[0][1])))}\n",
    "block_conversion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### How I will do this\n",
    "1. Loop over prediction dict\n",
    "2. If not empty, loop over cluster_groupings_dict\n",
    "3. If a box in cluster_groupings_dict belongs to the same cluster as the current object, append it to a dictionary which has a key of the cluster number. It is crucial to use the cluster number as the same number/op can occur twice and this will screw up the dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list,\n",
       "            {1: ['5', '+', 'A1', 'B1'],\n",
       "             2: ['8', '*', 'C1', 'D1', 'D2'],\n",
       "             3: ['2', '/', 'A2', 'A3'],\n",
       "             4: ['2', '-', 'B2', 'B3'],\n",
       "             5: ['9', '+', 'C2', 'C3', 'C4'],\n",
       "             6: ['2', '-', 'D3', 'D4'],\n",
       "             7: ['4', '*', 'A4', 'B4']})"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_ops_blocks_dict = defaultdict(list)\n",
    "\n",
    "for k,v in prediction_dict.items():\n",
    "    if len(v) > 0:\n",
    "        cluster = []\n",
    "        for k2, v2 in cluster_groupings_dict.items():\n",
    "            if v2 == cluster_groupings_dict[k]:\n",
    "                cluster.append(block_conversion[k2])\n",
    "        new_value = deepcopy(v)\n",
    "        new_value.extend(sorted(cluster))\n",
    "        num_ops_blocks_dict[cluster_groupings_dict[k]] = new_value\n",
    "        \n",
    "num_ops_blocks_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#SAVE TO FILE\n",
    "\n",
    "output_text = '4\\n'\n",
    "for _,v in sorted(num_ops_blocks_dict.items(),key=lambda x:x[0]):\n",
    "    for item in v:\n",
    "        output_text = output_text + item + ' '\n",
    "        \n",
    "    output_text = output_text + '\\n'\n",
    "\n",
    "\n",
    "with open('cv_puzzle.txt', 'w') as out:\n",
    "    out.write(output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(0, 0): 3,\n",
       " (0, 1): 4,\n",
       " (0, 2): 2,\n",
       " (0, 3): 1,\n",
       " (1, 0): 2,\n",
       " (1, 1): 1,\n",
       " (1, 2): 3,\n",
       " (1, 3): 4,\n",
       " (2, 0): 1,\n",
       " (2, 1): 3,\n",
       " (2, 2): 4,\n",
       " (2, 3): 2,\n",
       " (3, 0): 4,\n",
       " (3, 1): 2,\n",
       " (3, 2): 1,\n",
       " (3, 3): 3}"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "solve_puzzle('cv_puzzle.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "solution = solve_puzzle('cv_puzzle.txt',False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAI0AAAB/CAYAAADSBEG3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAEuRJREFUeJztnXtQVOX/x99nL4AG30WXEJEICiEJQyHTFFFTnLxMFyPR\nUsjasczRsBwZbwNqoZKalo2NlEo6WZJWahctuY02XkjERBlXvKSSXFYFFliXPef5/eHs/hbksue2\nZ5fOa2YH9uzu53n2nPd5Luc57/1QhBDIyLBBIXUFZNwPWTQyrJFFI8MaWTQyrJFFI8MaWTQyrJFF\nI8MaWTQyrJFFI8MaWTQyrFFJVfCIESNIXl4eFArHdUtRlEPva25uxt27dxEQEODwZxyFEIJ3330X\nMTExeOutt1rFJ4TYnlv/Wpdp2NSjvLwc4eHhrPaNIxBCYDKZoNVqYTabOe8YyUSjUCigUqlw7do1\nHDlyBAAwefJkBAQEdPgZR3e8SqWCSqWCWq0WpK72MAwDpVIJpVIJlUqFkpISFBYW4oUXXsBjjz0G\niqLaFQob0VjrL7RoAMBisYDveqPk3dPOnTvR2NiIgIAAqFQqEEJsD4PBgIaGBt5fUgwoioLJZEJy\ncjL69++PcePGwWQy2V43m822vwzDSFVNUZBcNOXl5Th06BC+++47eHh4gKIo22P79u0oLi4WvIsR\nCrVaDX9/f/zxxx+IiYmBWq0GIQS1tbWYNGkSiouLkZiYiJs3b0pdVUGRXDSZmZnYuXMnvLy8sH//\nflu/++qrr2LdunV45ZVXEBwcjEcffRQ9e/aEVqtFTEwMVq5cidu3b/Mq+/bt2/jyyy8xZcoU9O/f\nHz179oSvry9GjhyJbdu2ddrCEUJQV1eHuro6JCUl4fz582hubgYA+Pn5YcmSJXjuuedACMHrr78O\njUYDhUKB5ORkXnXujF27dkGhUEChUGDbtm2ilSO5aLKysnD16lXU1NSgT58+oCgKnp6e2LZtG2bN\nmgWj0YjAwEAkJCQgNTUVM2bMgFqtRkZGBqKjo3mdxbm5uZg9ezZOnjyJYcOGYcGCBUhMTERZWRl0\nOh2SkpI6/Xx9fT3q6+vRt29fNDQ0wGw2g6Io3LlzBxkZGdBoNPj5559RWlqKoKAgUVvM69evY968\nefDx8RG/ZbYfQzjzERcXR1paWsiNGzfIhg0byO7du0lzczOhaZowDEMYhiFlZWXkn3/+sW2zZ+nS\npYSiKDJ37lzSlqamJlJZWfnA9rbk5+eTgwcPPrC9qqqKBAcHE4VCQfbt29fqNZqmydtvv02++OIL\nYrFYyJEjR8iHH35ITpw4QSwWC6FpmphMJlJRUUGOHDlCioqKSHNzMykoKCAURZGZM2d2Wa8LFy4Q\nmqa7fJ89Y8eOJWFhYWTRokVEoVCQr776qt33NTU1EZVKRQiPYyfZ7Am4P5js27cv3nvvvVbbgPti\nHjBggO1/YjedBYCpU6ciMzMTer2ec/mjR49ud7u/vz/eeecdLF26FAUFBXj55ZfbrTtFURg9ejTG\njBlj204IgYeHB0JCQhAaGsq5bmzYtGkTCgoKUFBQYJuJionk3ZP9dQ2FQtFqIGzF2k/bs3//fgBA\ndHS0KPWyTtdVqvbPq/bqaf/c+l2s28XiwoULWLx4MVJTUxEXFydaOfZI2tIAeGDH22+3Z926dWhs\nbERdXR2Ki4tx9OhRDBo0CGlpaYLXiaZp5OTkgKIoPP/8852+t209u3ouJDRNY+bMmQgJCcFHH30k\nWjltkVw0jrJ+/XpUV1fbnk+YMAE7duyAVqsVvKy0tDSUlZVh8uTJSEhIEDy+UKxYsQKlpaU4duwY\nPD09nVau5N2To/z777+gaRq3bt3Cvn37UFFRgUGDBuHMmTOClvPpp59iw4YNiIyMxNdffy1obCE5\nceIEVq9ejYULF+KZZ55xatluIxorDz/8MF588UUcPnwYBoNB0OsemzdvRmpqKqKiopCXlwdfX1/B\nYgsJTdNITk5GREQEVq5c2eo14oSr524nGivBwcGIjIxEWVkZ74t8ALBx40bMnz8fTz31FPLy8uDv\n7y9ALcXBaDRCr9fjwoUL8PT0tE0UFAqFTUQ6nQ4KhQLvv/++4OW7zZimPSorKwEASqWSV5y1a9di\n8eLFiImJwe+//45evXoJUT3R8PT0hE6na/e106dPo6SkBCNHjkRERASeffZZwct3adHo9Xr06dMH\n//vf/1ptJ4Rg2bJlqK6uRlxcHDQaDecyVq1ahfT0dAwZMgSHDh1y2S7JHi8vL2zdurXd11asWIGS\nkhKkpKTgzTffFKV8lxbNL7/8gsWLFyMuLg6hoaHQarWoqqpCYWEhLl++jMDAwA53niPk5OQgPT0d\nKpUKI0aMwKZNmx54T0hICFJSUjjF/+mnn/Djjz8CAG7dugUA+PPPPzFr1iwA99eoPv74Y4617xix\nxzUuLZpx48ahoqICR48exZkzZ3D37l089NBDCA8PR0pKCubNm8erZbh69SooigJN0+0KBgBGjRrF\nWTRnzpxpNQOjKApXrlzBlStXANwXpBii6dZrTxaLhdX6iqM4uvbEBeva09atWx9YDxMKLmtPjiLE\n2pPbzp5kpEMWjQxrZNHIsEaygbDBYMDBgwcFHbRZY5lMJhiNRvj5+QEQbjZhvWn88uXLUCgUOHDg\ngCBx25ZRWVmJkJAQeHh4CB6fYRje+1wy0VRXV2PXrl2ijPT1ej2am5sRHR0t+PSTEIKLFy+ipqYG\nNTU1olhkDh48iKCgIJu7QUiampp4x5BMNE888QR27tzJ+2quPVaBfPLJJzAYDPjwww8F3+kMw2Du\n3LmIjY3t8Kos3/gBAQEIDw9HWFiYYPW37huTycT7RJJMNBRFQa1Ww2AwYMuWLfD19YVOp0PPnj1t\n7yFt7tbragdad4bVl6RWq1FaWoo9e/ZgwIABeO2116BUKjkZ2KwwDGPzJSmVSvz6668oKirCtGnT\nEB0dbbtZrO2BcbQsmqZt5QiJvR+LL5IOhAkhWLFiBYYPH47i4mIcPnzYth0A/v77b1RWVjr8Ze1v\nFbU+li5dipdeeglbtmzB9evXBa17VVUV0tPTkZKSgpSUFBiNRtvrNE3j1KlTMJvNnA+W0K2kUPEk\nFQ1FUVi1ahXi4+NRV1cHb29v22tmsxnnzp3DrVu3YLFYWn2uK6uG/c7JyclBZGQkjEYjPDw8bGJq\nbm7Gt99+i/nz5yM+Pp61xYSiKFgsFjQ2NsLLywsNDQ1oaGgAcF8w9fX1mD59OhISEhASEuJS9hu+\nSLqMQAhBjx49kJSUhPj4eMTHxwMA7t27h8TEROj1elAUhZEjRyI7OxtAa6uG/ZndNq5VOA0NDZg4\ncSLWrFljs/zeuXMHEydOxLVr11BTUwNvb28EBQWhvLycVf379euHNWvWYPfu3WhpabF1fadPn0Zy\ncjIuX76MmzdvIiEhAQMHDkRjYyOOHz+OjIwMZGdn4/jx4+jXrx+nfZebm4s5c+YgMDAQY8aMQXBw\nMKqqqrBv3z7odDr89ttv2LNnD6fYXSH52lNqaiqqq6uhUqmg1+sRGRkJT09PHDhwALm5uRgwYAAG\nDhxoe/+sWbPg5+eHKVOmYN26dR3GtZ5pOp0OoaGhuHTpEgwGA7RaLXr16oXjx4+joKAAjzzyCMLC\nwlBYWNjKVdAVhBCYzWbs378f48ePh6+vLzQaDQghiI2NxcmTJzF9+nTs2rULGo2mVeu3bNkyZGZm\nYvXq1di8eTOHvQZERETgwIEDmDRpUqvtmZmZGDJkCPbu3YsffvihXScFXyTvnqZNm4bU1FT069cP\nPXr0aHWXf3h4OHr37m17v9WqsX379lYD5vbiAvcP7AcffIDExEQEBgZCpVK1upF9zJgxePzxxznX\n3dPTEwsWLIDBYEBhYSG8vLxs8b28vLB8+fJ26zl16lQA4G2/aSsY4P/tN4QQFBQUcI7fGZK3NJ2d\n3YMHD7b939aq0Zm/x9rKKBQKTJgwodMBIN/BYVRUFKKioh7YrlarMXTo0HY/I7X9hi+Si8YRpLJq\nCIWr2m+44haiYWvVcLVfmehu9huXX7DkYtUQc7rJhe5mv3Fp0Uht1RCa7mK/cWnRcLVquFr31BZ3\nt9+49JiGq1XDHVohd7bfuLRopLZq8KE7229cWjRd0VGL4mj3JKbFxN3tN53h1qLpSByOdk9iWkzc\n3X7TKXysDHweYllYGIYhWVlZJC0tzfYzbEIitoXFYrEQX19fUl5eLnhsQmQLS4e4+uzJ3emWoiFu\nMHtyZyS/c0+seGIKR2xRWlfKhSzHPhbfllgy0YjRhbTqdxUKtxUlIM6tntZ9wxfJZk9msxm1tbWC\nuhGsNDY2oqGhAQaDQfDYhBAYjUbU19ejtrZW8PgMw4AQgr179yI4OFjw+G7tRgA6/mVPIeOKOSgW\nq+4AcOzYMZSVlT2QAohvXIvFYnM8cEUy0ajVavj5+Qne0hBC4O3tDZPJZHNYCnlwGYaBj48PNBoN\ntFqt4MKhaRpKpRLr169HWFgYGIax2WYAft+FkPt5J/bu3curjvLsyQWxWmcZhsGiRYuQlJTU6k5F\n+1ti2T4A/vunW4rG3SGEgGEYXLlyBd7e3sjKyoJOp7MdbOvrXA6+ELMylxYNV28PmyY8LS0N48aN\nQ3BwsODepPZgk14nNDQUy5cvR15eHmJjY23bKysrUVFRgW+++YaVb0uortSl1564envYnEkbN25E\nbGwsxo8fD39/f0G9SW1xxLNlj1KpxJIlS3Djxg3k5OQAuP/dvv/+e/z11184deoULl68yNm3xRk+\naxB8Ho6sPXFJrcN27enevXvtbu8oNRCftSdH0uvYrz2dPXuWaDQakpycTN544w3S0tLSqsyCggJy\n6dIl2/+OpAbq9mtPXL09bJrhjn4DRghvkj2OerbsiYqKwu3bt7Fjxw5kZ2c/kIlm1KhRnH1bfHBp\n0XRGZ94eIsDsSUhvEtf0Ou2lAnKFxViXHtN0hBjeHrG8SXw9W864SMkWtxRNV94eLjtYLG+SVOl1\nxMTtuidHvD1cuicxvElSptcRE7cSjTO8PUJ5k7qbZ8setxENG2+PEP0/X2+S1Ol1xMQtxjRsvT1C\nncl8vElSp9cRE5cXjZjeHjG9Se7s2eoKlxYNV2+Po92T2N6kzhCiNZQqNZBLi4art8fRAyK2N6kz\nhBh3SZUayKXXnrgg+546p9uvPXHFla6edke6pWiIm18HcXW6pWhkxEXS3AhCpJGxhxDSyt9jjS9k\ny2O9zVLsLtBab6ETalhj80Ey0ej1esyfP/+Be0T4QgjB2bNnYTQaHbo7ji0URSE/Px9PPvmkKPGt\niTQaGhpEie/WqXu8vb0xfPhwQUVjPYOefvppGI1GaLVawVsFiqJw7tw5mM1mmM1mUSwsAASPb219\n2+aZ4IJkogkICMD06dNt+QTMZjPUavUDIrK3XTiSuoeiKDQ1NaGurg4BAQGi5HsqKiqCRqNB7969\nRRONVqsVJX5zc7N7uxGs/XZRUREGDx5sa46tZwUAVlaNtjcsufPU2xnjJq5I/qsRFosF2dnZaGxs\nbJUYq7CwEHV1dbhx4wZKSkokrKVMWyRvabKysrBs2TL4+Pi0eu3evXsYOnQo4uPjkZWVhVGjRrHO\nycQFNr6kznBGPiZne7asSH6dJjc3F2PHjoVer8fnn38O4L6YoqKiYDKZUFVVhdzcXJSWliIoKEjU\nJtvel8S3nNzcXMyePRsnT57EsGHDsGDBAiQmJqKsrAw6nQ5JSUm867tx40Y0NTVh/PjxSE1NxYwZ\nM6BWq5GRkYHo6GjcvHmTdxntwmcNgs8jLi6OtLS0kJaWFmI2m0l0dDSpra0lDMOQlpYWMmfOHHL+\n/Hmydu1asnz5csIwDCtvT2VlZdcLMW1wxJfk6NoTF88WIezWnth6tgjpJmtPFEVBoVDgxIkTtpur\nlEolPvvsM0RERGDhwoVIT08XvR5cfEmd4Yx8TM7ybLVF8jGN9eHh4fFAZlx7z4+YcPUlcUXsfExi\n55OS/H4a68+cdTSGENsg5uxcUu7k2eoIyUUDtH89xVnXKJztSxIjH5Mz80kBLjB7khJn+5LEysfk\nrHxSVv6zonG2L8mdPFtd8Z8VjTN9Sc7OxyR0Pqm2uMSYRgqc5UuSIh8TIFw+qfb4z4rGGb4kd/Vs\ndYXLi0Yqbw/fcY3Y+Zik9Gy5vGik8vbwnfKLnY9JSs9Wt/M9EcJ97ckRZN+TC6w9ybgf3Vo0RET/\nk5ixhfplcXuEjCX5mEasnS+0daUjxCjDPqbQwhFiLU9S0VgsFlFWemmaBk3TgvuqgNY/MW9/e6pQ\nWGNaE2kIDd8MLABAOeNsbA+NRkPEWu+xWCywWCzw8vISJX5ZWRl8fHwczsfERriEEOTn52PIkCHw\n9vZmFdd6LO23tz2+NE0jPz8fhBDOZ5NkopFxX7r1QFhGHGTRyLBGFo0Ma2TRyLBGFo0Ma2TRyLBG\nFo0Ma2TRyLBGFo0Ma2TRyLBGFo0Ma2TRyLBGFo0Ma2TRyLBGFo0Ma2TRyLBGFo0Ma2TRyLBGFo0M\na2TRyLDm/wBXKt8m1VSFTQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x114162dd8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(2, 2), dpi=100)\n",
    "\n",
    "plt.axis('off')\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.imshow(sample4x4_crop, cmap=mpl.cm.Greys_r)\n",
    "for k,v in solution.items():\n",
    "    plt.annotate('{}'.format(v), xy=(k[0]*50+15,k[1]*50+35), fontsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Success!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "1 678\n",
      "1 456\n",
      "1 7\n",
      "1 6\n",
      "0 1\n",
      "4\n",
      "2 678\n",
      "2 456\n",
      "2 7\n",
      "2 6\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'min_index' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-255-b5526ffefeca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m123500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;31m#print('This is {}'.format(j))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m     \u001b[0mfind_answer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m456\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m678\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m123456\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-255-b5526ffefeca>\u001b[0m in \u001b[0;36mfind_answer\u001b[0;34m(full_number, current_number, coins, count)\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0;31m#print(min_index)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;31m#print(coins[min_index])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0mcurrent_number\u001b[0m\u001b[0;34m-=\u001b[0m\u001b[0mnew_coins\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmin_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m         \u001b[0mcount\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0;31m#print(current_number,count)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'min_index' referenced before assignment"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "memo = defaultdict(int)\n",
    "\n",
    "def find_answer(full_number, current_number, coins, count=0):\n",
    "    if current_number in memo:\n",
    "        memo[full_number]=count + memo[current_number]\n",
    "        return count + memo[number]\n",
    "    \n",
    "    if current_number == 0:\n",
    "        memo[full_number]=count\n",
    "        return count\n",
    "    \n",
    "    else:\n",
    "        coins = sorted(coins, reverse=True)\n",
    "        #print(coins)\n",
    "        mods = []\n",
    "        min_mod = 100000000\n",
    "        for coin in coins:\n",
    "            mods.append(current_number%coin)\n",
    "        \n",
    "        bad_coins = []\n",
    "        for i,coin in enumerate(coins):\n",
    "            for mod in mods:\n",
    "                if coin<mod:\n",
    "                    bad_coins.append(i)\n",
    "                    break\n",
    "        \n",
    "        new_coins = [coins[j] for j in range(len(coins)) if j not in bad_coins]\n",
    "        new_mods = [mods[j] for j in range(len(coins)) if j not in bad_coins]\n",
    "        \n",
    "        #print(mods)\n",
    "        print(len(new_mods))\n",
    "        for k, mod in enumerate(new_mods):\n",
    "            print(mod, new_coins[k])\n",
    "            if mod < min_mod and current_number-new_coins[k]>=0:\n",
    "                min_mod = mod\n",
    "                min_index = k\n",
    "        \n",
    "        #print(min_index)\n",
    "        #print(coins[min_index])\n",
    "        current_number-=new_coins[min_index]\n",
    "        count+=1\n",
    "        #print(current_number,count)\n",
    "        return find_answer(full_number,current_number,coins,count)\n",
    "\n",
    "for j in range(12):\n",
    "    #print('This is {}'.format(j))\n",
    "    find_answer(j, j, [1,6,7,456,678])\n",
    " \n",
    "memo[123456]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0\n",
      "1 1\n",
      "2 2\n",
      "3 3\n",
      "4 4\n",
      "5 5\n",
      "6 1\n",
      "7 1\n",
      "8 2\n",
      "9 3\n",
      "10 4\n",
      "11 5\n",
      "12 2\n",
      "13 3\n",
      "14 2\n",
      "15 3\n",
      "16 4\n",
      "17 5\n",
      "18 3\n",
      "19 4\n",
      "20 5\n",
      "21 3\n",
      "22 4\n",
      "23 5\n",
      "24 4\n",
      "25 5\n",
      "26 6\n",
      "27 7\n",
      "28 4\n",
      "29 5\n",
      "30 5\n",
      "31 6\n",
      "32 7\n",
      "33 8\n",
      "34 9\n",
      "35 5\n",
      "36 6\n",
      "37 7\n",
      "38 8\n",
      "39 9\n",
      "40 10\n",
      "41 11\n",
      "42 6\n",
      "43 7\n",
      "44 8\n",
      "45 9\n",
      "46 10\n",
      "47 11\n",
      "48 7\n",
      "49 7\n",
      "50 8\n",
      "51 9\n",
      "52 10\n",
      "53 11\n",
      "54 8\n",
      "55 9\n",
      "56 8\n",
      "57 9\n",
      "58 10\n",
      "59 11\n",
      "60 9\n",
      "61 10\n",
      "62 11\n",
      "63 9\n",
      "64 10\n",
      "65 11\n",
      "66 10\n",
      "67 11\n",
      "68 12\n",
      "69 13\n",
      "70 10\n",
      "71 11\n",
      "72 11\n",
      "73 12\n",
      "74 13\n",
      "75 14\n",
      "76 15\n",
      "77 11\n",
      "78 12\n",
      "79 13\n",
      "80 14\n",
      "81 15\n",
      "82 16\n",
      "83 17\n",
      "84 12\n",
      "85 13\n",
      "86 14\n",
      "87 15\n",
      "88 16\n",
      "89 17\n",
      "90 13\n",
      "91 13\n",
      "92 14\n",
      "93 15\n",
      "94 16\n",
      "95 17\n",
      "96 14\n",
      "97 15\n",
      "98 14\n",
      "99 15\n",
      "100 16\n",
      "101 17\n",
      "102 15\n",
      "103 16\n",
      "104 17\n",
      "105 15\n",
      "106 16\n",
      "107 17\n",
      "108 16\n",
      "109 17\n",
      "110 18\n",
      "111 19\n",
      "112 16\n",
      "113 17\n",
      "114 17\n",
      "115 18\n",
      "116 19\n",
      "117 20\n",
      "118 21\n",
      "119 17\n",
      "120 18\n",
      "121 19\n",
      "122 20\n",
      "123 21\n",
      "124 22\n",
      "125 23\n",
      "126 18\n",
      "127 19\n",
      "128 20\n",
      "129 21\n",
      "130 22\n",
      "131 23\n",
      "132 19\n",
      "133 19\n",
      "134 20\n",
      "135 21\n",
      "136 22\n",
      "137 23\n",
      "138 20\n",
      "139 21\n",
      "140 20\n",
      "141 21\n",
      "142 22\n",
      "143 23\n",
      "144 21\n",
      "145 22\n",
      "146 23\n",
      "147 21\n",
      "148 22\n",
      "149 23\n",
      "150 22\n",
      "151 23\n",
      "152 24\n",
      "153 25\n",
      "154 22\n",
      "155 23\n",
      "156 23\n",
      "157 24\n",
      "158 25\n",
      "159 26\n",
      "160 27\n",
      "161 23\n",
      "162 24\n",
      "163 25\n",
      "164 26\n",
      "165 27\n",
      "166 28\n",
      "167 29\n",
      "168 24\n",
      "169 25\n",
      "170 26\n",
      "171 27\n",
      "172 28\n",
      "173 29\n",
      "174 25\n",
      "175 25\n",
      "176 26\n",
      "177 27\n",
      "178 28\n",
      "179 29\n",
      "180 26\n",
      "181 27\n",
      "182 26\n",
      "183 27\n",
      "184 28\n",
      "185 29\n",
      "186 27\n",
      "187 28\n",
      "188 29\n",
      "189 27\n",
      "190 28\n",
      "191 29\n",
      "192 28\n",
      "193 29\n",
      "194 30\n",
      "195 31\n",
      "196 28\n",
      "197 29\n",
      "198 29\n",
      "199 30\n",
      "200 31\n",
      "201 32\n",
      "202 33\n",
      "203 29\n",
      "204 30\n",
      "205 31\n",
      "206 32\n",
      "207 33\n",
      "208 34\n",
      "209 35\n",
      "210 30\n",
      "211 31\n",
      "212 32\n",
      "213 33\n",
      "214 34\n",
      "215 35\n",
      "216 31\n",
      "217 31\n",
      "218 32\n",
      "219 33\n",
      "220 34\n",
      "221 35\n",
      "222 32\n",
      "223 33\n",
      "224 32\n",
      "225 33\n",
      "226 34\n",
      "227 35\n",
      "228 33\n",
      "229 34\n",
      "230 35\n",
      "231 33\n",
      "232 34\n",
      "233 35\n",
      "234 34\n",
      "235 35\n",
      "236 36\n",
      "237 37\n",
      "238 34\n",
      "239 35\n",
      "240 35\n",
      "241 36\n",
      "242 37\n",
      "243 38\n",
      "244 39\n",
      "245 35\n",
      "246 36\n",
      "247 37\n",
      "248 38\n",
      "249 39\n",
      "250 40\n",
      "251 41\n",
      "252 36\n",
      "253 37\n",
      "254 38\n",
      "255 39\n",
      "256 40\n",
      "257 41\n",
      "258 37\n",
      "259 37\n",
      "260 38\n",
      "261 39\n",
      "262 40\n",
      "263 41\n",
      "264 38\n",
      "265 39\n",
      "266 38\n",
      "267 39\n",
      "268 40\n",
      "269 41\n",
      "270 39\n",
      "271 40\n",
      "272 41\n",
      "273 39\n",
      "274 40\n",
      "275 41\n",
      "276 40\n",
      "277 41\n",
      "278 42\n",
      "279 43\n",
      "280 40\n",
      "281 41\n",
      "282 41\n",
      "283 42\n",
      "284 43\n",
      "285 44\n",
      "286 45\n",
      "287 41\n",
      "288 42\n",
      "289 43\n",
      "290 44\n",
      "291 45\n",
      "292 46\n",
      "293 47\n",
      "294 42\n",
      "295 43\n",
      "296 44\n",
      "297 45\n",
      "298 46\n",
      "299 47\n",
      "300 43\n",
      "301 43\n",
      "302 44\n",
      "303 45\n",
      "304 46\n",
      "305 47\n",
      "306 44\n",
      "307 45\n",
      "308 44\n",
      "309 45\n",
      "310 46\n",
      "311 47\n",
      "312 45\n",
      "313 46\n",
      "314 47\n",
      "315 45\n",
      "316 46\n",
      "317 47\n",
      "318 46\n",
      "319 47\n",
      "320 48\n",
      "321 49\n",
      "322 46\n",
      "323 47\n",
      "324 47\n",
      "325 48\n",
      "326 49\n",
      "327 50\n",
      "328 51\n",
      "329 47\n",
      "330 48\n",
      "331 49\n",
      "332 50\n",
      "333 51\n",
      "334 52\n",
      "335 53\n",
      "336 48\n",
      "337 49\n",
      "338 50\n",
      "339 51\n",
      "340 52\n",
      "341 53\n",
      "342 49\n",
      "343 49\n",
      "344 50\n",
      "345 51\n",
      "346 52\n",
      "347 53\n",
      "348 50\n",
      "349 51\n",
      "350 50\n",
      "351 51\n",
      "352 52\n",
      "353 53\n",
      "354 51\n",
      "355 52\n",
      "356 53\n",
      "357 51\n",
      "358 52\n",
      "359 53\n",
      "360 52\n",
      "361 53\n",
      "362 54\n",
      "363 55\n",
      "364 52\n",
      "365 53\n",
      "366 53\n",
      "367 54\n",
      "368 55\n",
      "369 56\n",
      "370 57\n",
      "371 53\n",
      "372 54\n",
      "373 55\n",
      "374 56\n",
      "375 57\n",
      "376 58\n",
      "377 59\n",
      "378 54\n",
      "379 55\n",
      "380 56\n",
      "381 57\n",
      "382 58\n",
      "383 59\n",
      "384 55\n",
      "385 55\n",
      "386 56\n",
      "387 57\n",
      "388 58\n",
      "389 59\n",
      "390 56\n",
      "391 57\n",
      "392 56\n",
      "393 57\n",
      "394 58\n",
      "395 59\n",
      "396 57\n",
      "397 58\n",
      "398 59\n",
      "399 57\n",
      "400 58\n",
      "401 59\n",
      "402 58\n",
      "403 59\n",
      "404 60\n",
      "405 61\n",
      "406 58\n",
      "407 59\n",
      "408 59\n",
      "409 60\n",
      "410 61\n",
      "411 62\n",
      "412 63\n",
      "413 59\n",
      "414 60\n",
      "415 61\n",
      "416 62\n",
      "417 63\n",
      "418 64\n",
      "419 65\n",
      "420 60\n",
      "421 61\n",
      "422 62\n",
      "423 63\n",
      "424 64\n",
      "425 65\n",
      "426 61\n",
      "427 61\n",
      "428 62\n",
      "429 63\n",
      "430 64\n",
      "431 65\n",
      "432 62\n",
      "433 63\n",
      "434 62\n",
      "435 63\n",
      "436 64\n",
      "437 65\n",
      "438 63\n",
      "439 64\n",
      "440 65\n",
      "441 63\n",
      "442 64\n",
      "443 65\n",
      "444 64\n",
      "445 65\n",
      "446 66\n",
      "447 67\n",
      "448 64\n",
      "449 65\n",
      "450 65\n",
      "451 66\n",
      "452 67\n",
      "453 68\n",
      "454 69\n",
      "455 65\n",
      "456 1\n",
      "457 2\n",
      "458 3\n",
      "459 4\n",
      "460 5\n",
      "461 6\n",
      "462 66\n",
      "463 67\n",
      "464 68\n",
      "465 69\n",
      "466 70\n",
      "467 71\n",
      "468 67\n",
      "469 67\n",
      "470 68\n",
      "471 69\n",
      "472 70\n",
      "473 71\n",
      "474 68\n",
      "475 69\n",
      "476 68\n",
      "477 69\n",
      "478 70\n",
      "479 71\n",
      "480 69\n",
      "481 70\n",
      "482 71\n",
      "483 69\n",
      "484 70\n",
      "485 71\n",
      "486 70\n",
      "487 71\n",
      "488 72\n",
      "489 73\n",
      "490 70\n",
      "491 71\n",
      "492 71\n",
      "493 72\n",
      "494 73\n",
      "495 74\n",
      "496 75\n",
      "497 71\n",
      "498 72\n",
      "499 73\n",
      "500 74\n",
      "501 75\n",
      "502 76\n",
      "503 77\n",
      "504 72\n",
      "505 73\n",
      "506 74\n",
      "507 75\n",
      "508 76\n",
      "509 77\n",
      "510 73\n",
      "511 73\n",
      "512 74\n",
      "513 75\n",
      "514 76\n",
      "515 77\n",
      "516 74\n",
      "517 75\n",
      "518 74\n",
      "519 75\n",
      "520 76\n",
      "521 77\n",
      "522 75\n",
      "523 76\n",
      "524 77\n",
      "525 75\n",
      "526 76\n",
      "527 77\n",
      "528 76\n",
      "529 77\n",
      "530 78\n",
      "531 79\n",
      "532 76\n",
      "533 77\n",
      "534 77\n",
      "535 78\n",
      "536 79\n",
      "537 80\n",
      "538 81\n",
      "539 77\n",
      "540 78\n",
      "541 79\n",
      "542 80\n",
      "543 81\n",
      "544 82\n",
      "545 83\n",
      "546 78\n",
      "547 79\n",
      "548 80\n",
      "549 81\n",
      "550 82\n",
      "551 83\n",
      "552 79\n",
      "553 79\n",
      "554 80\n",
      "555 81\n",
      "556 82\n",
      "557 83\n",
      "558 80\n",
      "559 81\n",
      "560 80\n",
      "561 81\n",
      "562 82\n",
      "563 83\n",
      "564 81\n",
      "565 82\n",
      "566 83\n",
      "567 81\n",
      "568 82\n",
      "569 83\n",
      "570 82\n",
      "571 83\n",
      "572 84\n",
      "573 85\n",
      "574 82\n",
      "575 83\n",
      "576 83\n",
      "577 84\n",
      "578 85\n",
      "579 86\n",
      "580 87\n",
      "581 83\n",
      "582 84\n",
      "583 85\n",
      "584 86\n",
      "585 87\n",
      "586 88\n",
      "587 89\n",
      "588 84\n",
      "589 85\n",
      "590 86\n",
      "591 87\n",
      "592 88\n",
      "593 89\n",
      "594 85\n",
      "595 85\n",
      "596 86\n",
      "597 87\n",
      "598 88\n",
      "599 89\n",
      "600 86\n",
      "601 87\n",
      "602 86\n",
      "603 87\n",
      "604 88\n",
      "605 89\n",
      "606 87\n",
      "607 88\n",
      "608 89\n",
      "609 87\n",
      "610 88\n",
      "611 89\n",
      "612 88\n",
      "613 89\n",
      "614 90\n",
      "615 91\n",
      "616 88\n",
      "617 89\n",
      "618 89\n",
      "619 90\n",
      "620 91\n",
      "621 92\n",
      "622 93\n",
      "623 89\n",
      "624 90\n",
      "625 91\n",
      "626 92\n",
      "627 93\n",
      "628 94\n",
      "629 95\n",
      "630 90\n",
      "631 91\n",
      "632 92\n",
      "633 93\n",
      "634 94\n",
      "635 95\n",
      "636 91\n",
      "637 91\n",
      "638 92\n",
      "639 93\n",
      "640 94\n",
      "641 95\n",
      "642 92\n",
      "643 93\n",
      "644 92\n",
      "645 93\n",
      "646 94\n",
      "647 95\n",
      "648 93\n",
      "649 94\n",
      "650 95\n",
      "651 93\n",
      "652 94\n",
      "653 95\n",
      "654 94\n",
      "655 95\n",
      "656 96\n",
      "657 97\n",
      "658 94\n",
      "659 95\n",
      "660 95\n",
      "661 96\n",
      "662 97\n",
      "663 98\n",
      "664 99\n",
      "665 95\n",
      "666 96\n",
      "667 97\n",
      "668 98\n",
      "669 99\n",
      "670 100\n",
      "671 101\n",
      "672 96\n",
      "673 97\n",
      "674 98\n",
      "675 99\n",
      "676 100\n",
      "677 101\n",
      "678 1\n",
      "679 97\n",
      "680 98\n",
      "681 99\n",
      "682 100\n",
      "683 101\n",
      "684 2\n",
      "685 3\n",
      "686 98\n",
      "687 99\n",
      "688 100\n",
      "689 101\n",
      "690 3\n",
      "691 4\n",
      "692 5\n",
      "693 99\n",
      "694 100\n",
      "695 101\n",
      "696 4\n",
      "697 5\n",
      "698 6\n",
      "699 7\n",
      "700 100\n",
      "701 101\n",
      "702 5\n",
      "703 6\n",
      "704 7\n",
      "705 8\n",
      "706 9\n",
      "707 101\n",
      "708 6\n",
      "709 7\n",
      "710 8\n",
      "711 9\n",
      "712 10\n",
      "713 11\n",
      "714 102\n",
      "715 103\n",
      "716 104\n",
      "717 105\n",
      "718 106\n",
      "719 107\n",
      "720 103\n",
      "721 103\n",
      "722 104\n",
      "723 105\n",
      "724 106\n",
      "725 107\n",
      "726 104\n",
      "727 105\n",
      "728 104\n",
      "729 105\n",
      "730 106\n",
      "731 107\n",
      "732 105\n",
      "733 106\n",
      "734 107\n",
      "735 105\n",
      "736 106\n",
      "737 107\n",
      "738 106\n",
      "739 107\n",
      "740 108\n",
      "741 109\n",
      "742 106\n",
      "743 107\n",
      "744 107\n",
      "745 108\n",
      "746 109\n",
      "747 110\n",
      "748 111\n",
      "749 107\n",
      "750 108\n",
      "751 109\n",
      "752 110\n",
      "753 111\n",
      "754 112\n",
      "755 113\n",
      "756 108\n",
      "757 109\n",
      "758 110\n",
      "759 111\n",
      "760 112\n",
      "761 113\n",
      "762 109\n",
      "763 109\n",
      "764 110\n",
      "765 111\n",
      "766 112\n",
      "767 113\n",
      "768 110\n",
      "769 111\n",
      "770 110\n",
      "771 111\n",
      "772 112\n",
      "773 113\n",
      "774 111\n",
      "775 112\n",
      "776 113\n",
      "777 111\n",
      "778 112\n",
      "779 113\n",
      "780 112\n",
      "781 113\n",
      "782 114\n",
      "783 115\n",
      "784 112\n",
      "785 113\n",
      "786 113\n",
      "787 114\n",
      "788 115\n",
      "789 116\n",
      "790 117\n",
      "791 113\n",
      "792 114\n",
      "793 115\n",
      "794 116\n",
      "795 117\n",
      "796 118\n",
      "797 119\n",
      "798 114\n",
      "799 115\n",
      "800 116\n",
      "801 117\n",
      "802 118\n",
      "803 119\n",
      "804 115\n",
      "805 115\n",
      "806 116\n",
      "807 117\n",
      "808 118\n",
      "809 119\n",
      "810 116\n",
      "811 117\n",
      "812 116\n",
      "813 117\n",
      "814 118\n",
      "815 119\n",
      "816 117\n",
      "817 118\n",
      "818 119\n",
      "819 117\n",
      "820 118\n",
      "821 119\n",
      "822 118\n",
      "823 119\n",
      "824 120\n",
      "825 121\n",
      "826 118\n",
      "827 119\n",
      "828 119\n",
      "829 120\n",
      "830 121\n",
      "831 122\n",
      "832 123\n",
      "833 119\n",
      "834 120\n",
      "835 121\n",
      "836 122\n",
      "837 123\n",
      "838 124\n",
      "839 125\n",
      "840 120\n",
      "841 121\n",
      "842 122\n",
      "843 123\n",
      "844 124\n",
      "845 125\n",
      "846 121\n",
      "847 121\n",
      "848 122\n",
      "849 123\n",
      "850 124\n",
      "851 125\n",
      "852 122\n",
      "853 123\n",
      "854 122\n",
      "855 123\n",
      "856 124\n",
      "857 125\n",
      "858 123\n",
      "859 124\n",
      "860 125\n",
      "861 123\n",
      "862 124\n",
      "863 125\n",
      "864 124\n",
      "865 125\n",
      "866 126\n",
      "867 127\n",
      "868 124\n",
      "869 125\n",
      "870 125\n",
      "871 126\n",
      "872 127\n",
      "873 128\n",
      "874 129\n",
      "875 125\n",
      "876 126\n",
      "877 127\n",
      "878 128\n",
      "879 129\n",
      "880 130\n",
      "881 131\n",
      "882 126\n",
      "883 127\n",
      "884 128\n",
      "885 129\n",
      "886 130\n",
      "887 131\n",
      "888 127\n",
      "889 127\n",
      "890 128\n",
      "891 129\n",
      "892 130\n",
      "893 131\n",
      "894 128\n",
      "895 129\n",
      "896 128\n",
      "897 129\n",
      "898 130\n",
      "899 131\n",
      "900 129\n",
      "901 130\n",
      "902 131\n",
      "903 129\n",
      "904 130\n",
      "905 131\n",
      "906 130\n",
      "907 131\n",
      "908 132\n",
      "909 133\n",
      "910 130\n",
      "911 131\n",
      "912 2\n",
      "913 3\n",
      "914 4\n",
      "915 5\n",
      "916 6\n",
      "917 131\n",
      "918 3\n",
      "919 4\n",
      "920 5\n",
      "921 6\n",
      "922 7\n",
      "923 8\n",
      "924 132\n",
      "925 133\n",
      "926 134\n",
      "927 135\n",
      "928 136\n",
      "929 137\n",
      "930 133\n",
      "931 133\n",
      "932 134\n",
      "933 135\n",
      "934 136\n",
      "935 137\n",
      "936 134\n",
      "937 135\n",
      "938 134\n",
      "939 135\n",
      "940 136\n",
      "941 137\n",
      "942 135\n",
      "943 136\n",
      "944 137\n",
      "945 135\n",
      "946 136\n",
      "947 137\n",
      "948 136\n",
      "949 137\n",
      "950 138\n",
      "951 139\n",
      "952 136\n",
      "953 137\n",
      "954 137\n",
      "955 138\n",
      "956 139\n",
      "957 140\n",
      "958 141\n",
      "959 137\n",
      "960 138\n",
      "961 139\n",
      "962 140\n",
      "963 141\n",
      "964 142\n",
      "965 143\n",
      "966 138\n",
      "967 139\n",
      "968 140\n",
      "969 141\n",
      "970 142\n",
      "971 143\n",
      "972 139\n",
      "973 139\n",
      "974 140\n",
      "975 141\n",
      "976 142\n",
      "977 143\n",
      "978 140\n",
      "979 141\n",
      "980 140\n",
      "981 141\n",
      "982 142\n",
      "983 143\n",
      "984 141\n",
      "985 142\n",
      "986 143\n",
      "987 141\n",
      "988 142\n",
      "989 143\n",
      "990 142\n",
      "991 143\n",
      "992 144\n",
      "993 145\n",
      "994 142\n",
      "995 143\n",
      "996 143\n",
      "997 144\n",
      "998 145\n",
      "999 146\n"
     ]
    }
   ],
   "source": [
    "for k,v in memo.items():\n",
    "    if k == 1000:\n",
    "        break\n",
    "    print(k,v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py35tensor",
   "language": "python",
   "name": "py35tensor"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
