{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is this?\n",
    "\n",
    "Because MNIST does not contain symbols (X/-+) I needed to make my own. I made images of the digits and symbols in 10 fonts, size 28x28 pixels. These files are contained in the folder 'base_images_artificial/'. This file takes those images, and exports them into the folder 'distorted_from_artificial/' after applying multiple distortions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import string\n",
    "import random\n",
    "import math\n",
    "from hashlib import sha1\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from scipy import ndimage as ndi\n",
    "from scipy.misc import imsave\n",
    "\n",
    "from skimage.filters import gabor, gaussian\n",
    "from skimage.transform import resize, warp\n",
    "from skimage.util import random_noise\n",
    "from skimage.morphology import dilation, erosion, rectangle, diamond, disk\n",
    "from skimage.transform._geometric import ProjectiveTransform\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random string generator for file names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def id_generator(size=6, chars=string.ascii_uppercase + string.digits):\n",
    "    return ''.join(random.choice(chars) for _ in range(size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_image(folder, image):\n",
    "    suffix = id_generator()\n",
    "    while suffix in UNIQUE_IDS:\n",
    "        suffix = id_generator()\n",
    "    UNIQUE_IDS.add(suffix)\n",
    "    extension = '.jpg'\n",
    "    filename = \"_\".join([folder, suffix]) + extension\n",
    "    output_file = os.path.join(SAVED_IMAGE_DIR, folder, filename)\n",
    "\n",
    "    imsave(output_file, image)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BASE_IMAGE_DIR = 'base_images_artificial/'\n",
    "SAVED_IMAGE_DIR = 'distorted_from_artificial/'\n",
    "DIR_LIST = ['0','1','2','3','4','5','6','7','8','9','X','plus','minus','div']\n",
    "IMAGE_SIZE = 28\n",
    "UNIQUE_IDS = set()\n",
    "UNIQUE_IMAGES = set()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function for cleaning out the folders where new images will be saved to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clear_saved_filtered_images():\n",
    "    for folder in DIR_LIST:\n",
    "        for image in os.listdir(SAVED_IMAGE_DIR + folder):\n",
    "            image_file = os.path.join(SAVED_IMAGE_DIR, folder, image)\n",
    "            os.remove(image_file)\n",
    "    \n",
    "    #Reinitialize UNIQUE_IDS and UNIQUE_IMAGES\n",
    "    UNIQUE_IDS.clear()\n",
    "    UNIQUE_IMAGES.clear()\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def apply_filters_and_save():\n",
    "    \n",
    "    for folder in DIR_LIST:\n",
    "        dataset = np.ndarray(shape=(10, IMAGE_SIZE, IMAGE_SIZE),dtype=np.float32)\n",
    "\n",
    "        #Read each image from the folder in BASE_IMAGE_DIR\n",
    "        image_index=0\n",
    "        for image in os.listdir(BASE_IMAGE_DIR + folder):\n",
    "            image_file = os.path.join(BASE_IMAGE_DIR, folder, image)\n",
    "            try:\n",
    "                image_data = ndi.imread(image_file, mode = 'L')\n",
    "                image_data = resize(image_data, (IMAGE_SIZE,IMAGE_SIZE))\n",
    "                #print(image_data.shape)\n",
    "\n",
    "                assert image_data.shape == (IMAGE_SIZE, IMAGE_SIZE)\n",
    "\n",
    "                dataset[image_index, :, :] = image_data\n",
    "                image_index+=1\n",
    "            except IOError as e:\n",
    "                print('Could not read:', image_file, ':', e, '- it\\'s ok, skipping.')\n",
    "                \n",
    "        #Apply filters and save each time\n",
    "        #Sha1 function is used for hashing the numpy arrays and preventing\n",
    "        #Exact duplicates of images\n",
    "        for image in dataset:\n",
    "            #default image\n",
    "            save_image(folder, image)\n",
    "            UNIQUE_IMAGES.add(sha1(image))\n",
    "            \n",
    "            \n",
    "            #random_noise\n",
    "            new_image = random_noise(image, 'gaussian')\n",
    "            if sha1(new_image) not in UNIQUE_IMAGES:\n",
    "                save_image(folder, new_image)\n",
    "                UNIQUE_IMAGES.add(sha1(new_image))\n",
    "            \n",
    "            #translate image slightly. inversion is for preventing 0's from filling border\n",
    "            for i in range(-2,3):\n",
    "                for j in range(-2,3):\n",
    "                    new_image = 1-warp(1-image,ProjectiveTransform(np.array([[1, 0, i],[0,1,j],[0,0,1]])))\n",
    "                    if sha1(new_image) not in UNIQUE_IMAGES:\n",
    "                        save_image(folder, new_image)\n",
    "                        UNIQUE_IMAGES.add(sha1(new_image))\n",
    "            \n",
    "            #erosions and dilations\n",
    "            for i in range(1,2):    \n",
    "                #rectangle/squares\n",
    "                for j in range(1,2):\n",
    "                    new_image = erosion(image, rectangle(i,i))\n",
    "                    if sha1(new_image) not in UNIQUE_IMAGES:\n",
    "                        save_image(folder, new_image)\n",
    "                        UNIQUE_IMAGES.add(sha1(new_image))\n",
    "\n",
    "                #circles\n",
    "                new_image = erosion(image, disk(i))\n",
    "                if sha1(new_image) not in UNIQUE_IMAGES:\n",
    "                    save_image(folder, new_image)\n",
    "                    UNIQUE_IMAGES.add(sha1(new_image))\n",
    "            \n",
    "            #gaussian filter\n",
    "            for sig in range(1,11, 1):   \n",
    "                new_image = gaussian(image, sig*.1)\n",
    "                if sha1(new_image) not in UNIQUE_IMAGES:\n",
    "                    save_image(folder, new_image)\n",
    "                    UNIQUE_IMAGES.add(sha1(new_image))\n",
    "                \n",
    "            #image = gabor(image, 2, 1*math.pi/10)[1]\n",
    "\n",
    "clear_saved_filtered_images()\n",
    "apply_filters_and_save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
