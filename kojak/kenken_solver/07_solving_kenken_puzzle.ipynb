{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is this?\n",
    "In this file I piece together all of the components from the previous jupyter notebooks. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below code was edited from code I found on a [reddit post](https://www.reddit.com/r/dailyprogrammer/comments/3snorf/20151113_challenge_240_hard_kenken_solver/). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Puzzle 1:\n",
      "1 4 3 5 2 6\n",
      "3 5 2 6 4 1\n",
      "4 6 1 3 5 2\n",
      "5 3 6 2 1 4\n",
      "6 2 4 1 3 5\n",
      "2 1 5 4 6 3\n",
      "Puzzle 2:\n",
      "3 2 1 4\n",
      "4 1 3 2\n",
      "2 3 4 1\n",
      "1 4 2 3\n"
     ]
    }
   ],
   "source": [
    "from functools import reduce\n",
    "import operator\n",
    "\n",
    "def check(board, cage_map, cell, i):\n",
    "    val, op, coords = cage_map[cell]\n",
    "    vals = [board[coord] for coord in coords]\n",
    "    if not all(vals):\n",
    "        return True\n",
    "    if op == \"=\":\n",
    "        return i == val\n",
    "    elif op == \"+\":\n",
    "        return sum(vals) == val\n",
    "    elif op == \"*\":\n",
    "        return reduce(operator.mul, vals) == val\n",
    "    elif op == \"-\":\n",
    "        return abs(vals[0] - vals[1]) == val\n",
    "    elif op == \"/\":\n",
    "        bigger, smaller = max(vals), min(vals)\n",
    "        return bigger % smaller == 0 and bigger // smaller == val\n",
    "\n",
    "def recurse(sz, cage_map, board, cell_list, depth=0):\n",
    "    if depth == len(cell_list):\n",
    "        return True\n",
    "    cell = cell_list[depth]\n",
    "    X, Y = cell\n",
    "    used = {board[(x, Y)] for x in range(sz)} | {board[(X, y)] for y in range(sz)}\n",
    "    for i in set(range(1, sz+1)) - used:\n",
    "        board[cell] = i\n",
    "        if not check(board, cage_map, cell, i):\n",
    "            continue\n",
    "        if recurse(sz, cage_map, board, cell_list, depth+1):\n",
    "            return True\n",
    "    board[cell] = None\n",
    "\n",
    "def read_file(file_name):\n",
    "    sz, *cages = open(file_name).read().splitlines()\n",
    "    sz = int(sz)\n",
    "\n",
    "    name_to_coord = lambda name: ('ABCDEFGHI'.index(name[0]), int(name[1])-1)\n",
    "    cages = [\n",
    "        (int(val), operator, [name_to_coord(coord) for coord in coords])\n",
    "        for val, operator, *coords in map(str.split, cages)\n",
    "    ]\n",
    "    \n",
    "    cage_map = {\n",
    "        coord: cage\n",
    "        for cage in cages\n",
    "        for coord in cage[2]\n",
    "    }\n",
    "\n",
    "    board = {\n",
    "        coord: None for coord in cage_map\n",
    "    }\n",
    "    cell_list = list(sorted(board))\n",
    "    \n",
    "    return sz, cage_map, board, cell_list\n",
    "    \n",
    "\n",
    "def solve_puzzle(file_name, verbose=False):\n",
    "    sz, cage_map, board, cell_list = read_file(file_name)\n",
    "    recurse(sz, cage_map, board, cell_list)\n",
    "\n",
    "    if verbose:\n",
    "        for y in range(sz):\n",
    "            line = \" \".join(str(board[(x, y)]) for x in range(sz))\n",
    "            print(line)\n",
    "    else:\n",
    "        return board\n",
    "        \n",
    "print('Puzzle 1:')\n",
    "solve_puzzle(\"puzzle.txt\", True)\n",
    "print('Puzzle 2:')\n",
    "solve_puzzle(\"puzzle2.txt\", True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's put everthing together now so we can get a **text file** lke those used in the above code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from copy import deepcopy\n",
    "import os\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from scipy import ndimage as ndi\n",
    "from scipy.misc import imsave\n",
    "\n",
    "from skimage import feature\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.transform import resize\n",
    "from skimage.morphology import erosion, dilation, rectangle, square\n",
    "from skimage.measure import find_contours\n",
    "\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "IMAGE_FILE = 'sample4x4_1.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def binarize(matrix, threshold=0.3):\n",
    "    temp = deepcopy(matrix)\n",
    "    for m in range(len(temp)):\n",
    "        for n in range(len(temp[m])):\n",
    "            if temp[m][n] < threshold:\n",
    "                temp[m][n] = 0.0\n",
    "            else:\n",
    "                temp[m][n] = 1.0\n",
    "                \n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "choosing  (25, 25)\n",
      "currently labeled  []\n",
      "path found :  [(75, 75), (25, 75), (25, 25)]\n",
      "assigning label :  1 \n",
      "\n",
      "choosing  (25, 75)\n",
      "currently labeled  [(75, 75), (25, 75), (25, 25)]\n",
      "its already in the set\n",
      "choosing  (25, 125)\n",
      "currently labeled  [(25, 25), (25, 75), (75, 75)]\n",
      "path found :  [(25, 125), (75, 125), (25, 175)]\n",
      "assigning label :  2 \n",
      "\n",
      "choosing  (25, 175)\n",
      "currently labeled  [(25, 125), (25, 75), (75, 75), (25, 25), (75, 125), (25, 175)]\n",
      "its already in the set\n",
      "choosing  (75, 25)\n",
      "currently labeled  [(25, 125), (25, 75), (75, 75), (25, 25), (75, 125), (25, 175)]\n",
      "path found :  [(125, 25), (75, 25)]\n",
      "assigning label :  3 \n",
      "\n",
      "choosing  (75, 75)\n",
      "currently labeled  [(25, 125), (25, 75), (75, 75), (25, 25), (75, 125), (25, 175), (125, 25), (75, 25)]\n",
      "its already in the set\n",
      "choosing  (75, 125)\n",
      "currently labeled  [(25, 125), (25, 75), (75, 75), (25, 25), (75, 125), (25, 175), (125, 25), (75, 25)]\n",
      "its already in the set\n",
      "choosing  (75, 175)\n",
      "currently labeled  [(25, 125), (25, 75), (75, 75), (25, 25), (75, 125), (25, 175), (125, 25), (75, 25)]\n",
      "path found :  [(75, 175)]\n",
      "assigning label :  4 \n",
      "\n",
      "choosing  (125, 25)\n",
      "currently labeled  [(25, 125), (25, 75), (75, 175), (75, 75), (25, 25), (75, 125), (25, 175), (125, 25), (75, 25)]\n",
      "its already in the set\n",
      "choosing  (125, 75)\n",
      "currently labeled  [(25, 125), (25, 75), (75, 75), (25, 25), (75, 125), (125, 25), (25, 175), (75, 175), (75, 25)]\n",
      "path found :  [(175, 75), (175, 25), (125, 75)]\n",
      "assigning label :  5 \n",
      "\n",
      "choosing  (125, 125)\n",
      "currently labeled  [(25, 125), (25, 75), (75, 175), (75, 75), (175, 25), (25, 25), (75, 125), (125, 75), (175, 75), (25, 175), (125, 25), (75, 25)]\n",
      "path found :  [(125, 175), (125, 125)]\n",
      "assigning label :  6 \n",
      "\n",
      "choosing  (125, 175)\n",
      "currently labeled  [(25, 125), (125, 175), (25, 75), (75, 75), (125, 125), (175, 25), (25, 25), (75, 125), (125, 75), (175, 75), (125, 25), (25, 175), (75, 175), (75, 25)]\n",
      "its already in the set\n",
      "choosing  (175, 25)\n",
      "currently labeled  [(25, 125), (25, 75), (75, 175), (75, 75), (125, 125), (175, 25), (25, 25), (75, 125), (125, 75), (175, 75), (75, 25), (25, 175), (125, 25), (125, 175)]\n",
      "its already in the set\n",
      "choosing  (175, 75)\n",
      "currently labeled  [(25, 125), (125, 175), (25, 75), (75, 75), (125, 125), (175, 25), (25, 25), (75, 125), (125, 75), (175, 75), (125, 25), (25, 175), (75, 175), (75, 25)]\n",
      "its already in the set\n",
      "choosing  (175, 125)\n",
      "currently labeled  [(25, 125), (25, 75), (75, 175), (75, 75), (125, 125), (175, 25), (25, 25), (75, 125), (125, 75), (175, 75), (75, 25), (25, 175), (125, 25), (125, 175)]\n",
      "path found :  [(175, 125), (175, 175)]\n",
      "assigning label :  7 \n",
      "\n",
      "choosing  (175, 175)\n",
      "currently labeled  [(25, 125), (125, 175), (25, 75), (75, 75), (125, 125), (175, 25), (25, 25), (75, 125), (125, 75), (175, 75), (125, 25), (175, 125), (25, 175), (75, 175), (75, 25), (175, 175)]\n",
      "its already in the set\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQQAAAEACAYAAABVmQgcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1136053c8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "###########################\n",
    "#####IMPORT THE IMAGE######\n",
    "###########################\n",
    "sample4x4_orig = ndi.imread(IMAGE_FILE, mode='L')\n",
    "sample4x4 = resize(sample4x4_orig, (200,200))\n",
    "#plt.imshow(sample4x4, cmap=mpl.cm.Greys_r)\n",
    "\n",
    "binar = deepcopy(sample4x4)\n",
    "binar = binarize(binar)\n",
    "#plt.imshow(binar, cmap=mpl.cm.Greys_r)\n",
    "\n",
    "###########################\n",
    "#####CROP THE IMAGE########\n",
    "###########################\n",
    "# up left\n",
    "cond = False\n",
    "for m in range(7):\n",
    "    for n in range(7):\n",
    "        if binar[m][n] == 0:\n",
    "            up_left = [m,n]\n",
    "            cond = True\n",
    "            break\n",
    "    if cond==True:\n",
    "        break\n",
    "        \n",
    "# low right\n",
    "cond = False\n",
    "for m in range(199,192,-1):\n",
    "    for n in range(199,192,-1):\n",
    "        #print(m,n, binar[m][n])\n",
    "        if binar[m][n] == 0:\n",
    "            low_right = [m,n]\n",
    "            cond = True\n",
    "            break\n",
    "    if cond==True:\n",
    "        break\n",
    "\n",
    "sample4x4_crop = resize(sample4x4[up_left[0]:low_right[0]+1,up_left[1]:low_right[1]+1], (200,200))\n",
    "binar = binarize(sample4x4_crop)\n",
    "plt.imshow(binar, cmap=mpl.cm.Greys_r)\n",
    "\n",
    "################################################\n",
    "#####APPLY FILTERS TO REMOVE NUM/SYMBOLS########\n",
    "################################################\n",
    "selem = rectangle(2,2)\n",
    "dil = dilation(binar, selem)\n",
    "#dil = erosion(dil)\n",
    "#plt.imshow(dil, cmap=mpl.cm.Greys_r)\n",
    "\n",
    "dil = binarize(dil)\n",
    "#plt.imshow(dil, cmap=mpl.cm.Greys_r)\n",
    "\n",
    "cluster_image = deepcopy(dil)\n",
    "\n",
    "for i in range(4):\n",
    "    for j in range(4):\n",
    "        cluster_image[i*50+5:i*50+40,j*50+3:j*50+38] = np.zeros((35,35))+1\n",
    "        \n",
    "#plt.imshow(cluster_image, cmap=mpl.cm.Greys_r)\n",
    "\n",
    "##################################\n",
    "#####GET CLUSTER LOCATIONS########\n",
    "##################################\n",
    "\n",
    "#GENERATE CENTERS OF EACH BOX\n",
    "CENTROIDS = [[[25+50*i,25+50*j] for j in range(0,4)] for i in range(0,4)]\n",
    "\n",
    "#LINK BOX CENTERS TO GRID LOCATIONS I.E. (25,175) = (0,3)\n",
    "CLUSTER_LOC_DICT = defaultdict(list)\n",
    "\n",
    "for m in range(len(CENTROIDS)):\n",
    "    for n in range(len(CENTROIDS[m])):\n",
    "        CLUSTER_LOC_DICT[tuple(CENTROIDS[m][n])] = (m,n)\n",
    "\n",
    "#CREATE A DICTIONARY OF THE LOCATIONS OF NEIGHBORS OF EACH BOX\n",
    "NEIGHBOR_PAIRS = []\n",
    "\n",
    "for m in range(len(CENTROIDS)):\n",
    "    for n in range(len(CENTROIDS[m])):\n",
    "        #skip right edge\n",
    "        if n < (len(CENTROIDS[m])-1):\n",
    "            NEIGHBOR_PAIRS.append([CENTROIDS[m][n], CENTROIDS[m][n+1]])\n",
    "        #skip bottom edge\n",
    "        if m < (len(CENTROIDS)-1):\n",
    "            NEIGHBOR_PAIRS.append([CENTROIDS[m][n], CENTROIDS[m+1][n]])\n",
    "        #skip top edge\n",
    "        if m > 0:\n",
    "            NEIGHBOR_PAIRS.append([CENTROIDS[m][n], CENTROIDS[m-1][n]])\n",
    "        #skip left edge\n",
    "        if n > 0:\n",
    "            NEIGHBOR_PAIRS.append([CENTROIDS[m][n], CENTROIDS[m][n-1]]) \n",
    "            \n",
    "NEIGHBORS_DICT = defaultdict(list)\n",
    "\n",
    "for link in NEIGHBOR_PAIRS:\n",
    "    NEIGHBORS_DICT[tuple(link[0])].append(link[1])\n",
    "\n",
    "    \n",
    "#CREATE CLASS FOR WALKING THROUGH IMAGE AND RETURNING \n",
    "class cluster_grouper(object):\n",
    "    \n",
    "    def __init__ (self, image):\n",
    "        self.image_arr = image\n",
    "        # unique_label is the current # of unique labels used\n",
    "        self.unique_label = 1\n",
    "\n",
    "        # labeled_boxes keeps track of the boxes that have already been labeled\n",
    "        self.labeled_boxes = []\n",
    "\n",
    "        # create label_dict to store each boxes location\n",
    "        self.label_dict = {tuple(v):0 for _,v in CLUSTER_LOC_DICT.items()}\n",
    "                \n",
    "    \n",
    "        \n",
    "    def check_neighbors(self, box_to_check, path=[]):\n",
    "    #if neighbor is unlabeled and connected, \n",
    "    #step to that one, \n",
    "    #append current cell to path, \n",
    "    #call check neighbors\n",
    "        #check neighbors to see if any paths are blocked append T/F to if path blocked\n",
    "        if box_to_check not in path:\n",
    "            path.append(box_to_check)\n",
    "        \n",
    "        for neighbor in NEIGHBORS_DICT[box_to_check]:\n",
    "            # print(neighbor)\n",
    "            # skip a neighbor that you've come from\n",
    "            if tuple(neighbor) not in path:\n",
    "                top = box_to_check[0]\n",
    "                bottom = neighbor[0]\n",
    "                left = box_to_check[1]\n",
    "                right = neighbor[1]\n",
    "                \n",
    "                # need to check if top/bottom or left/right are same value, need to add 1\n",
    "                if top == bottom:\n",
    "                    bottom +=1\n",
    "                if left == right:\n",
    "                    right +=1\n",
    "                    \n",
    "                # also swap top/bottom or left/right if matching upwards or leftwards\n",
    "                if right < left:\n",
    "                    left,right = right,left\n",
    "                if top > bottom:\n",
    "                    top,bottom = bottom,top\n",
    "                \n",
    "                # if there is a black pixel in path, skip\n",
    "                if 0 in self.image_arr[top:bottom,left:right].flatten():\n",
    "                    continue\n",
    "                # else check the neighbor and extend path of result recursively\n",
    "                else:\n",
    "                    path.extend(self.check_neighbors(tuple(neighbor), path))\n",
    "                    path = list(set(path))\n",
    "                               \n",
    "        return path\n",
    "    \n",
    "    def execute(self):\n",
    "        for box in sorted(NEIGHBORS_DICT.keys(), key=lambda x: x):\n",
    "            #only clusters that haven't been labeled should appear not labeled,\n",
    "            #once an unlabeled cluster is found, all boxes in that cluster should be labeled\n",
    "            print('choosing ',box)\n",
    "            print('currently labeled ',self.labeled_boxes)\n",
    "            if box not in self.labeled_boxes:\n",
    "                #print(box)\n",
    "                connected_path = self.check_neighbors(box, path=[])\n",
    "                #get only unique boxes\n",
    "                print('path found : ', connected_path)\n",
    "                connected_path = set(connected_path)\n",
    "                #assign each box in the path a label\n",
    "                for connected_box in connected_path:\n",
    "                    self.label_dict[CLUSTER_LOC_DICT[connected_box]] = self.unique_label\n",
    "                    self.labeled_boxes.append(tuple(connected_box))\n",
    "                #increment the label\n",
    "                print('assigning label : ',self.unique_label, '\\n')\n",
    "                self.unique_label += 1\n",
    "            else:\n",
    "                print('its already in the set')\n",
    "            \n",
    "            self.labeled_boxes = list(set(self.labeled_boxes))\n",
    "        return self.label_dict\n",
    "\n",
    "#PASS THE CLUSTER IMAGE TO A NEW INSTANCE OF THE CLUSTER_GROUPER AND EXECUTE\n",
    "#THIS WILL RETURN A DICTIONARY WITH THE CLUSTER LABEL(VALUE) FOR EACH BOX(KEY)\n",
    "cluster_groupings_dict = cluster_grouper(cluster_image).execute()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identifying the numbers with TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 numbers/symbols found in quadrant 0,0\n",
      "0 numbers/symbols found in quadrant 0,1\n",
      "2 numbers/symbols found in quadrant 0,2\n",
      "0 numbers/symbols found in quadrant 0,3\n",
      "2 numbers/symbols found in quadrant 1,0\n",
      "0 numbers/symbols found in quadrant 1,1\n",
      "0 numbers/symbols found in quadrant 1,2\n",
      "1 numbers/symbols found in quadrant 1,3\n",
      "0 numbers/symbols found in quadrant 2,0\n",
      "3 numbers/symbols found in quadrant 2,1\n",
      "2 numbers/symbols found in quadrant 2,2\n",
      "0 numbers/symbols found in quadrant 2,3\n",
      "0 numbers/symbols found in quadrant 3,0\n",
      "0 numbers/symbols found in quadrant 3,1\n",
      "2 numbers/symbols found in quadrant 3,2\n",
      "0 numbers/symbols found in quadrant 3,3\n",
      "15 numbers/symbols found in image\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWIAAAD/CAYAAADL09xTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrCE2DMMomP8P/HmxGoWg9LUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x113799c50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "##############################################\n",
    "#####IMPORT TENSOR FLOW GRAPH AND DATA########\n",
    "##############################################\n",
    "\n",
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def conv2d(x, W):\n",
    "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],\n",
    "                            strides=[1, 2, 2, 1], padding='SAME')\n",
    "    \n",
    "\n",
    "with tf.Graph().as_default():\n",
    "    x = tf.placeholder(tf.float32, shape=[None, 784])\n",
    "    y_ = tf.placeholder(tf.float32, shape=[None, 14])\n",
    "    W = tf.Variable(tf.zeros([784,14]))\n",
    "    b = tf.Variable(tf.zeros([14]))\n",
    "\n",
    "    #Inference\n",
    "    with tf.name_scope('hidden1'):\n",
    "        W_conv1 = weight_variable([5, 5, 1, 32])\n",
    "        b_conv1 = bias_variable([32])\n",
    "        x_image = tf.reshape(x, [-1,28,28,1])\n",
    "        hidden1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)\n",
    "\n",
    "    with tf.name_scope('hidden2'):\n",
    "        h_pool1 = max_pool_2x2(hidden1)\n",
    "        W_conv2 = weight_variable([5, 5, 32, 64])\n",
    "        b_conv2 = bias_variable([64])\n",
    "        h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n",
    "\n",
    "    with tf.name_scope('fully_connected'):\n",
    "        h_pool2 = max_pool_2x2(h_conv2)\n",
    "        W_fc1 = weight_variable([7 * 7 * 64, 1024])\n",
    "        b_fc1 = bias_variable([1024])\n",
    "        h_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*64])\n",
    "        fully_connected = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)\n",
    "\n",
    "    with tf.name_scope('dropout'):\n",
    "        keep_prob = tf.placeholder(tf.float32)\n",
    "        dropout = tf.nn.dropout(fully_connected, keep_prob)\n",
    "\n",
    "    with tf.name_scope('softmax'):\n",
    "        W_fc2 = weight_variable([1024, 14])\n",
    "        b_fc2 = bias_variable([14])\n",
    "        y_conv=tf.nn.softmax(tf.matmul(dropout, W_fc2) + b_fc2)\n",
    "\n",
    "    #Loss\n",
    "    cross_entropy = -tf.reduce_sum(y_*tf.log(y_conv), name='xentropy')\n",
    "\n",
    "    #Training\n",
    "    tf.scalar_summary(cross_entropy.op.name, cross_entropy)\n",
    "    global_step=tf.Variable(0,name='global_step',trainable=False)\n",
    "    train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy,global_step=global_step)\n",
    "\n",
    "    #Evaluation\n",
    "    correct_prediction = tf.equal(tf.argmax(y_conv,1), tf.argmax(y_,1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "    #Prediction\n",
    "    prediction = tf.argmax(y_conv,1)\n",
    "\n",
    "    #Initialization\n",
    "    sess = tf.Session()\n",
    "    init = tf.initialize_all_variables()\n",
    "    saver = tf.train.Saver()\n",
    "\n",
    "    sess.run(init)\n",
    "\n",
    "    #Restore\n",
    "    saver.restore(sess,\"model_newest.ckpt\")\n",
    "    \n",
    "################################################################\n",
    "#####PRE PROCESS THE IMAGE FOR ISOLATING NUMBERS/SYMBOLS########\n",
    "################################################################\n",
    "    \n",
    "def pre_process_image(image_file):\n",
    "    #get the image and resize\n",
    "    image_data = ndi.imread(image_file, mode = 'L')\n",
    "    resized_image = resize(image_data, (200,200))\n",
    "\n",
    "    #apply the transformations from 01_basic_image_tests.ipynb\n",
    "    binar = deepcopy(resized_image)\n",
    "    binar = binarize(binar, 0.6)\n",
    "\n",
    "    # Get the upleft and lowright black pixels for croping to corners\n",
    "    # up left\n",
    "    cond = False\n",
    "    for m in range(10):\n",
    "        for n in range(10):\n",
    "            if binar[m][n] == 0:\n",
    "                up_left = [m,n]\n",
    "                cond = True\n",
    "                break\n",
    "        if cond==True:\n",
    "            break\n",
    "\n",
    "    # low right\n",
    "    cond = False\n",
    "    for m in range(199,189,-1):\n",
    "        for n in range(199,189,-1):\n",
    "            #print(m,n, binar[m][n])\n",
    "            if binar[m][n] == 0:\n",
    "                low_right = [m,n]\n",
    "                cond = True\n",
    "                break\n",
    "        if cond==True:\n",
    "            break\n",
    "\n",
    "    resized_image = resize(resized_image[up_left[0]:low_right[0]+1,up_left[1]:low_right[1]+1], (200,200))\n",
    "    binar = binarize(resized_image, 0.4)\n",
    "\n",
    "    undilated = deepcopy(binar)\n",
    "\n",
    "    #dilate the binarized image\n",
    "    selem = rectangle(1,2)\n",
    "    dil = dilation(binar, selem)\n",
    "\n",
    "    #binarize dilation\n",
    "    dil = binarize(dil)\n",
    "\n",
    "    #final = dil\n",
    "\n",
    "    final = deepcopy(dil)\n",
    "    for i in range(4):\n",
    "        for j in range(4):\n",
    "            final[i*50+3:i*50+25,j*50+3:j*50+44] = undilated[i*50+3:i*50+25,j*50+3:j*50+44]\n",
    "\n",
    "    #Try to remove all borders and grid lines in the image. \n",
    "    #Do this by scanning over rows and cols and if more than 25%\n",
    "    #of the pixels are <= 0.45 then set the entire row to 1(white)\n",
    "\n",
    "    #first rows\n",
    "    for row in range(len(final)):\n",
    "        count = 0\n",
    "        for pixel in final[row,:]:\n",
    "            if pixel == 0:\n",
    "                count += 1\n",
    "        if count >= 48:\n",
    "            final[row,:] = final[row,:]*0 + 1\n",
    "\n",
    "    #columns\n",
    "    for col in range(len(final[0,:])):\n",
    "        count = 0\n",
    "        for pixel in final[:,col]:\n",
    "            if pixel == 0:\n",
    "                count += 1\n",
    "        if count >= 48:\n",
    "            final[:,col] = final[:,col]*0 + 1\n",
    "            \n",
    "    #add some final erosion (black) to fill out numbers and ensure they're connected\n",
    "    final = binarize(erosion(final, rectangle(1,2)),.0000001)\n",
    "    \n",
    "    return final\n",
    "\n",
    "#APPLY PRE PROCESS TO DESIRED IMAGE\n",
    "final = pre_process_image(IMAGE_FILE)\n",
    "\n",
    "################################################################\n",
    "#####ISOLATE LOCATIONS OF EACH NUM/SYM IN EACH BOX############## \n",
    "#####       AND PREDICT USING TENSOR FLOW         ##############\n",
    "################################################################\n",
    "\n",
    "#the regions in the image that will be searched for contours\n",
    "regions_of_interest = [final[3:39,3:46],\n",
    "                      final[3:39,53:96],\n",
    "                      final[3:39,103:146],\n",
    "                      final[3:39,153:196],\n",
    "                      final[53:89,3:46],\n",
    "                      final[53:89,53:96],\n",
    "                      final[53:89,103:146],\n",
    "                      final[53:89,153:196],\n",
    "                      final[103:139,3:46],\n",
    "                      final[103:139,53:96],\n",
    "                      final[103:139,103:146],\n",
    "                      final[103:139,153:196],\n",
    "                      final[153:189,3:46],\n",
    "                      final[153:189,53:96],\n",
    "                      final[153:189,103:146],\n",
    "                      final[153:189,153:196]\n",
    "                      ]\n",
    "\n",
    "#get the contour lines and make a bounding box of each contour\n",
    "total_images_found = 0\n",
    "fig = plt.figure()\n",
    "\n",
    "#x_count and y_count is used for plotting the images\n",
    "#and also for saving the results to prediction_dict\n",
    "x_count = 0\n",
    "y_count = 0\n",
    "prediction_dict = defaultdict(list)\n",
    "plot_counter = 1\n",
    "\n",
    "#Conversion used for converting the index of the argmax returned\n",
    "#from tensorflow into a string value\n",
    "conversion = {0:'0',1:'1',2:'2',3:'3',4:'4',5:'5',6:'6',7:'7',8:'8',9:'9',10:'*', 11:'+',12:'-',13:'/'}\n",
    "\n",
    "for region in regions_of_interest:  \n",
    "    #Results is where the sub-ROIs will be stored\n",
    "    results = []\n",
    "    ctrs = find_contours(region, .9)\n",
    "    rects = [np.array(\n",
    "            [[min(ctr, key=lambda x: x[0])[0],min(ctr, key=lambda x: x[1])[1]],\n",
    "             [min(ctr, key=lambda x: x[0])[0],max(ctr, key=lambda x: x[1])[1]],\n",
    "             [max(ctr, key=lambda x: x[0])[0],max(ctr, key=lambda x: x[1])[1]],\n",
    "             [max(ctr, key=lambda x: x[0])[0],min(ctr, key=lambda x: x[1])[1]],\n",
    "             [min(ctr, key=lambda x: x[0])[0],min(ctr, key=lambda x: x[1])[1]]])\n",
    "              for ctr in ctrs]\n",
    "\n",
    "    #print(rects)\n",
    "\n",
    "    #loop over the bounding boxes and store that region, the regions will need \n",
    "    #to be filtered so that there aren't regions within regions\n",
    "    for rect in rects:\n",
    "        try:\n",
    "            pt1 = rect[0][0] #m min\n",
    "            pt2 = rect[2][0] #m max\n",
    "            pt3 = rect[0][1] #n min\n",
    "            pt4 = rect[1][1] #n max\n",
    "            results.append([pt1,pt2,pt3,pt4])\n",
    "\n",
    "        except:\n",
    "            print('There was an error')\n",
    "\n",
    "\n",
    "    #filter out a result contained in another result\n",
    "    #This isn't very efficient and will likely need a better\n",
    "    #algorithm for images taken with a camera but it works well for now\n",
    "    for result in results:\n",
    "        temp = [res for res in results if res != result]\n",
    "        for other in temp:\n",
    "            if result[0] >= other[0] and result[1] <= other[1] and\\\n",
    "            result[2] >= other[2] and result[3] <= other[3]:\n",
    "                try:\n",
    "                    results.remove(result)\n",
    "                except ValueError as e:\n",
    "                    print('Error removing result from results, ', e)\n",
    "\n",
    "    #combine those with similar midpoints (mainly used for finding division symbols)\n",
    "    midpoints = [(result[3]-result[2])/2+result[2] for result in results]\n",
    "    \n",
    "    new_results = []\n",
    "    for i,result in enumerate(results):\n",
    "        diff = [j for j, m in enumerate(midpoints) if abs(m-midpoints[i]) < 3]\n",
    "        #need to reinitialize new_results between loops\n",
    "        if len(diff) > 1:\n",
    "            new_results = [result for j,result in enumerate(results) if j not in diff]\n",
    "            similar_obj = np.array([results[j] for j in diff])\n",
    "            new_object = np.array([min(similar_obj[:,0]),\n",
    "                                  max(similar_obj[:,1]),\n",
    "                                  min(similar_obj[:,2]),\n",
    "                                  max(similar_obj[:,3])])\n",
    "            #print(new_object)\n",
    "            new_results.append(list(new_object))\n",
    "\n",
    "            break\n",
    "        else:\n",
    "            continue\n",
    "    \n",
    "    #assign new_results to results if new results were obtained\n",
    "    try:\n",
    "        if len(new_results) > 0:\n",
    "            results = new_results\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    #Sort the results by furthest box to the left \n",
    "    results = sorted(results, key=lambda x: x[2])\n",
    "    \n",
    "    #now make a new prediction on the results:\n",
    "    new_results = []\n",
    "    for result in results:\n",
    "        new_res = deepcopy(result)\n",
    "        roi = region[int(result[0]):int(result[1])+1, int(result[2]):int(result[3])+1] \n",
    "        roi = resize(roi, (28, 28)).reshape(1,784)\n",
    "        nbr = prediction.eval(feed_dict={x:roi, keep_prob:1.0}, session=sess)[0]\n",
    "        prediction_dict[(x_count,y_count)].append(conversion[nbr])\n",
    "        new_res.append(conversion[nbr])\n",
    "        new_results.append(new_res)\n",
    "\n",
    "        \n",
    "    try:\n",
    "        if len(new_results) > 0:\n",
    "            results = new_results\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    #Set the value of a box to an empty list in prediction_dict if no results\n",
    "    if len(results) == 0:\n",
    "        prediction_dict[(x_count,y_count)] = []\n",
    "\n",
    "    #Plot all of the subplots\n",
    "    plt.subplot(4,4,plot_counter)\n",
    "    plot_counter+=1\n",
    "    plt.imshow(region, interpolation='nearest', cmap=plt.cm.gray)\n",
    "\n",
    "    '''for contour in rects:\n",
    "        plt.plot(contour[:, 1], contour[:, 0], linewidth=2)'''\n",
    "\n",
    "    z = 0\n",
    "    for res in results:\n",
    "        plt.annotate('{}'.format(res[4]), xy=(10+z*5,25))\n",
    "        z+=1\n",
    "    \n",
    "    #Loop again over the filtered results, count how many there are\n",
    "    num_sym_found = 0\n",
    "    for result in results:\n",
    "        num_sym_found += 1      \n",
    "\n",
    "    print('{} numbers/symbols found in quadrant {},{}'.format(num_sym_found, x_count,y_count))\n",
    "    y_count+=1\n",
    "    if y_count == 4:\n",
    "        y_count = 0\n",
    "        x_count += 1\n",
    "    total_images_found+=num_sym_found\n",
    "\n",
    "print('{} numbers/symbols found in image'.format(total_images_found))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the text file\n",
    "The key pieces of info we have now is cluster_groupings_dict and prediction_dict. Now combine these two to get the text file.\n",
    "\n",
    "General format of the text file is:\n",
    "\n",
    "```\n",
    "4\n",
    "16 * A1 B1\n",
    "7 + C1 D1\n",
    "2 - A2 A3\n",
    "4 = D2\n",
    "...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(0, 0): 1,\n",
       " (0, 1): 1,\n",
       " (0, 2): 2,\n",
       " (0, 3): 2,\n",
       " (1, 0): 3,\n",
       " (1, 1): 1,\n",
       " (1, 2): 2,\n",
       " (1, 3): 4,\n",
       " (2, 0): 3,\n",
       " (2, 1): 5,\n",
       " (2, 2): 6,\n",
       " (2, 3): 6,\n",
       " (3, 0): 5,\n",
       " (3, 1): 5,\n",
       " (3, 2): 7,\n",
       " (3, 3): 7}"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_groupings_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list,\n",
       "            {(0, 0): ['1', '6', '*'],\n",
       "             (0, 1): [],\n",
       "             (0, 2): ['7', '+'],\n",
       "             (0, 3): [],\n",
       "             (1, 0): ['2', '-'],\n",
       "             (1, 1): [],\n",
       "             (1, 2): [],\n",
       "             (1, 3): ['4'],\n",
       "             (2, 0): [],\n",
       "             (2, 1): ['1', '2', '*'],\n",
       "             (2, 2): ['2', '/'],\n",
       "             (2, 3): [],\n",
       "             (3, 0): [],\n",
       "             (3, 1): [],\n",
       "             (3, 2): ['2', '/'],\n",
       "             (3, 3): []})"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list,\n",
       "            {(0, 0): ['16', '*'],\n",
       "             (0, 1): [],\n",
       "             (0, 2): ['7', '+'],\n",
       "             (0, 3): [],\n",
       "             (1, 0): ['2', '-'],\n",
       "             (1, 1): [],\n",
       "             (1, 2): [],\n",
       "             (1, 3): ['4', '='],\n",
       "             (2, 0): [],\n",
       "             (2, 1): ['12', '*'],\n",
       "             (2, 2): ['2', '/'],\n",
       "             (2, 3): [],\n",
       "             (3, 0): [],\n",
       "             (3, 1): [],\n",
       "             (3, 2): ['2', '/'],\n",
       "             (3, 3): []})"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for k,v in prediction_dict.items():\n",
    "    if len(v) > 0:\n",
    "        if v[-1] not in '+-*/':\n",
    "            operation = '='\n",
    "            number = ''.join(v[:])\n",
    "        else:\n",
    "            operation = v[-1]\n",
    "            number = ''.join(v[:-1])\n",
    "        \n",
    "        prediction_dict[k] = [number, operation]\n",
    "        \n",
    "prediction_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a new dictionary for the naming convention of squares in the KenKen algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(0, 0): 'A1',\n",
       " (0, 1): 'B1',\n",
       " (0, 2): 'C1',\n",
       " (0, 3): 'D1',\n",
       " (1, 0): 'A2',\n",
       " (1, 1): 'B2',\n",
       " (1, 2): 'C2',\n",
       " (1, 3): 'D2',\n",
       " (2, 0): 'A3',\n",
       " (2, 1): 'B3',\n",
       " (2, 2): 'C3',\n",
       " (2, 3): 'D3',\n",
       " (3, 0): 'A4',\n",
       " (3, 1): 'B4',\n",
       " (3, 2): 'C4',\n",
       " (3, 3): 'D4'}"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kenken4_4blocks = ['A1', 'B1', 'C1', 'D1',\n",
    "                   'A2', 'B2', 'C2', 'D2',\n",
    "                   'A3', 'B3', 'C3', 'D3',\n",
    "                   'A4', 'B4', 'C4', 'D4']\n",
    "block_conversion = {x[0]:kenken4_4blocks[i] for i, x in \n",
    "                    enumerate(sorted(prediction_dict.items(), key=lambda z:(z[0][0], z[0][1])))}\n",
    "block_conversion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### How I will do this\n",
    "1. Loop over prediction dict\n",
    "2. If not empty, loop over cluster_groupings_dict\n",
    "3. If a box in cluster_groupings_dict belongs to the same cluster as the current object, append it to a dictionary which has a key of the cluster number. It is crucial to use the cluster number as the same number/op can occur twice and this will screw up the dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list,\n",
       "            {1: ['16', '*', 'A1', 'B1', 'B2'],\n",
       "             2: ['7', '+', 'C1', 'C2', 'D1'],\n",
       "             3: ['2', '-', 'A2', 'A3'],\n",
       "             4: ['4', '=', 'D2'],\n",
       "             5: ['12', '*', 'A4', 'B3', 'B4'],\n",
       "             6: ['2', '/', 'C3', 'D3'],\n",
       "             7: ['2', '/', 'C4', 'D4']})"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_ops_blocks_dict = defaultdict(list)\n",
    "\n",
    "for k,v in prediction_dict.items():\n",
    "    if len(v) > 0:\n",
    "        cluster = []\n",
    "        for k2, v2 in cluster_groupings_dict.items():\n",
    "            if v2 == cluster_groupings_dict[k]:\n",
    "                cluster.append(block_conversion[k2])\n",
    "        new_value = deepcopy(v)\n",
    "        new_value.extend(sorted(cluster))\n",
    "        num_ops_blocks_dict[cluster_groupings_dict[k]] = new_value\n",
    "        \n",
    "num_ops_blocks_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#SAVE TO FILE\n",
    "\n",
    "output_text = '4\\n'\n",
    "for _,v in sorted(num_ops_blocks_dict.items(),key=lambda x:x[0]):\n",
    "    for item in v:\n",
    "        output_text = output_text + item + ' '\n",
    "        \n",
    "    output_text = output_text + '\\n'\n",
    "\n",
    "\n",
    "with open('cv_puzzle.txt', 'w') as out:\n",
    "    out.write(output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 4 1 3\n",
      "1 2 3 4\n",
      "3 1 4 2\n",
      "4 3 2 1\n"
     ]
    }
   ],
   "source": [
    "solve_puzzle('cv_puzzle.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Success!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py35tensor",
   "language": "python",
   "name": "py35tensor"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
